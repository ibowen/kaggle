{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing, pipeline, metrics, grid_search, cross_validation\n",
    "import time\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data finished in 0.058s\n",
      "Loading test data finished in 0.074s\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "start = time.time() \n",
    "train = pd.read_csv('train.csv')\n",
    "print (\"Loading train data finished in %0.3fs\" % (time.time() - start))        \n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "print (\"Loading test data finished in %0.3fs\" % (time.time() - start))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'AnimalID', u'Name', u'DateTime', u'OutcomeType', u'OutcomeSubtype',\n",
       "       u'AnimalType', u'SexuponOutcome', u'AgeuponOutcome', u'Breed',\n",
       "       u'Color'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ID', u'Name', u'DateTime', u'AnimalType', u'SexuponOutcome',\n",
       "       u'AgeuponOutcome', u'Breed', u'Color'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OutcomeType, OutcomeSubtype not shown in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnimalID          object\n",
       "Name              object\n",
       "DateTime          object\n",
       "OutcomeType       object\n",
       "OutcomeSubtype    object\n",
       "AnimalType        object\n",
       "SexuponOutcome    object\n",
       "AgeuponOutcome    object\n",
       "Breed             object\n",
       "Color             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classifiy columns into categorical, numerical, label and id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label_col': ['OutcomeType'], 'id_col': ['AnimalID'], 'numerical_cols': [], 'categorical_cols': ['Name', 'DateTime', 'AnimalType', 'SexuponOutcome', 'AgeuponOutcome', 'Breed', 'Color']}\n"
     ]
    }
   ],
   "source": [
    "# seperate column names by categorical, numerical, label, and id\n",
    "data_types = train.dtypes  \n",
    "categorical_cols = list(data_types[data_types=='object'].index)\n",
    "numerical_cols = list(data_types[data_types=='int64'].index) + list(data_types[data_types=='float64'].index)\n",
    "\n",
    "dict_cols = dict()\n",
    "\n",
    "# categorical columns\n",
    "dict_cols['categorical_cols'] = categorical_cols\n",
    "dict_cols['categorical_cols'].remove('AnimalID') # remove ids\n",
    "dict_cols['categorical_cols'].remove('OutcomeType') # remove labels\n",
    "dict_cols['categorical_cols'].remove('OutcomeSubtype')\n",
    "\n",
    "# numeric columns\n",
    "dict_cols['numerical_cols'] = numerical_cols\n",
    "\n",
    "# id columns\n",
    "dict_cols['id_col'] = ['AnimalID']\n",
    "\n",
    "# label columns\n",
    "dict_cols['label_col'] = ['OutcomeType']\n",
    "\n",
    "print dict_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Label encoding categorical columns for train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 26729\n",
      "test data size: 11456\n"
     ]
    }
   ],
   "source": [
    "# Merge train and test\n",
    "dict_cols['train_size'] = train.shape[0]\n",
    "dict_cols['test_size'] = test.shape[0]\n",
    "print 'train data size: %s' % dict_cols['train_size']\n",
    "print 'test data size: %s' % dict_cols['test_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38185, 8)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.concat([train[dict_cols['categorical_cols'] + dict_cols['numerical_cols'] + dict_cols['label_col']]\n",
    "                     , test[dict_cols['categorical_cols'] + dict_cols['numerical_cols']]\n",
    "                    ])\n",
    "\n",
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoding column: Name\n",
      "Label encoding column: DateTime\n",
      "Label encoding column: AnimalType\n",
      "Label encoding column: SexuponOutcome\n",
      "Label encoding column: AgeuponOutcome\n",
      "Label encoding column: Breed\n",
      "Label encoding column: Color\n"
     ]
    }
   ],
   "source": [
    "# label encoding categorical columns\n",
    "for col in dict_cols['categorical_cols']:\n",
    "    print(\"Label encoding column: %s\" % (col))\n",
    "    LBL = preprocessing.LabelEncoder()\n",
    "    LBL.fit(full_data[col])\n",
    "    full_data[col] = LBL.transform(full_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {nan: 0, 'Return_to_owner': 4, 'Transfer': 5, 'Adoption': 1, 'Euthanasia': 3, 'Died': 2}\n"
     ]
    }
   ],
   "source": [
    "# record the label mapping\n",
    "LBL = preprocessing.LabelEncoder()\n",
    "LBL.fit(full_data['OutcomeType'])\n",
    "label_mapping = dict(zip(full_data['OutcomeType'].unique(), LBL.transform(full_data['OutcomeType'].unique())))\n",
    "print(\"Label mapping: %s\" % (label_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoding column: OutcomeType\n"
     ]
    }
   ],
   "source": [
    "# label encode categorical label\n",
    "full_data['OutcomeType'] = LBL.transform(full_data['OutcomeType'])\n",
    "print \"Label encoding column: OutcomeType\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38185, 8)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Search models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Defind function to grid search the best model\n",
    "def search_model(train_x, train_y, est, param_grid, n_jobs, cv, refit=False):\n",
    "    model = grid_search.GridSearchCV(estimator  = est, \n",
    "                                     param_grid = param_grid, \n",
    "                                     scoring = 'log_loss', \n",
    "                                     verbose = 10, \n",
    "                                     n_jobs  = n_jobs, \n",
    "                                     iid = True, # is identically distributed \n",
    "                                     refit = refit,\n",
    "                                     cv = cv)\n",
    "    # Fit Grid Search Model\n",
    "    model.fit(train_x, train_y)\n",
    "    print(\"Best score: %0.3f\" % model.best_score_)\n",
    "    print(\"Best parameters set:\", model.best_params_)\n",
    "    print(\"Scores:\", model.grid_scores_)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = full_data[:dict_cols['train_size']][dict_cols['categorical_cols']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = full_data[:dict_cols['train_size']][dict_cols['label_col']].values.reshape(dict_cols['train_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'criterion':['gini', 'entropy'], 'n_estimators':[500], 'random_state' : [1234]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "[CV] n_estimators=500, random_state=1234, criterion=gini .............\n",
      "[CV] n_estimators=500, random_state=1234, criterion=gini .............\n",
      "[CV] n_estimators=500, random_state=1234, criterion=gini .............\n",
      "[CV] n_estimators=500, random_state=1234, criterion=gini .............\n",
      "[CV] n_estimators=500, random_state=1234, criterion=entropy ..........\n",
      "[CV] n_estimators=500, random_state=1234, criterion=entropy ..........\n",
      "[CV] n_estimators=500, random_state=1234, criterion=entropy ..........\n",
      "[CV] n_estimators=500, random_state=1234, criterion=entropy ..........\n",
      "[CV]  n_estimators=500, random_state=1234, criterion=gini, score=-0.947547 -  22.5s\n",
      "[CV]  n_estimators=500, random_state=1234, criterion=gini, score=-0.993872 -  22.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   8 | elapsed:   22.6s remaining:   -2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=500, random_state=1234, criterion=gini, score=-0.964288 -  22.9s\n",
      "[CV]  n_estimators=500, random_state=1234, criterion=gini, score=-0.966900 -  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   8 | elapsed:   22.9s remaining:   -2.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   8 | elapsed:   23.1s remaining:   -2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=500, random_state=1234, criterion=entropy, score=-0.988436 -  32.2s\n",
      "[CV]  n_estimators=500, random_state=1234, criterion=entropy, score=-0.959271 -  32.2s\n",
      "[CV]  n_estimators=500, random_state=1234, criterion=entropy, score=-0.977050 -  32.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   8 | elapsed:   32.3s remaining:   -3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   8 | elapsed:   32.3s remaining:   -3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   8 | elapsed:   32.5s remaining:   -3.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=500, random_state=1234, criterion=entropy, score=-0.993002 -  32.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   8 | elapsed:   32.7s remaining:   -3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   32.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.968\n",
      "('Best parameters set:', {'n_estimators': 500, 'random_state': 1234, 'criterion': 'gini'})\n",
      "('Scores:', [mean: -0.96816, std: 0.01660, params: {'n_estimators': 500, 'random_state': 1234, 'criterion': 'gini'}, mean: -0.97944, std: 0.01301, params: {'n_estimators': 500, 'random_state': 1234, 'criterion': 'entropy'}])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [500], 'random_state': [1234], 'criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=False, scoring='log_loss',\n",
       "       verbose=10)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_model(train_X\n",
    "            , train_y\n",
    "            , RandomForestClassifier()\n",
    "            , param_grid\n",
    "            , -1\n",
    "            , 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homeworks:\n",
    "1. Apply One-Hot-Encoder for all the categorical columns then remove the original categoricals.\n",
    "2. Check the difference between Label Encoding and One-Hot-Encoding.\n",
    "    Tips: scikit-learn one-hot-encoder or pandas get_dummies()\n",
    "    Question: what if there are levels existing in traning data but not in test data?\n",
    "3. Create submissions using both encoders, as well as a submission that is the average of them. Submit all of the three to see if ensemble helps "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
