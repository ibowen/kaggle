{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing, pipeline, metrics, grid_search, cross_validation\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Week 3 we will be focused on XGBoost tuning and will be using engineered features from week 2 which by the end of this notebook will lead you to a score between 0.736-0.739. But feel free to use whichever features that  work for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load train and test data and output full data and column dictionary\n",
    "def load_data():\n",
    "    # Load data\n",
    "    start = time.time() \n",
    "    train = pd.read_csv('./data/train.csv', parse_dates=['DateTime'])\n",
    "    print (\"Loading train data finished in %0.3fs\" % (time.time() - start))        \n",
    "\n",
    "    test = pd.read_csv('./data/test.csv', parse_dates=['DateTime'])\n",
    "    print (\"Loading test data finished in %0.3fs\" % (time.time() - start))  \n",
    "\n",
    "    # seperate column names by categorical, numerical, label, and id\n",
    "    data_types = train.dtypes  \n",
    "    categorical_cols = list(data_types[data_types=='object'].index) + list(data_types[data_types=='datetime64[ns]'].index)\n",
    "    numerical_cols = list(data_types[data_types=='int64'].index) + list(data_types[data_types=='float64'].index)\n",
    "\n",
    "    dict_cols = dict()\n",
    "    # categorical columns\n",
    "    dict_cols['categorical_cols'] = categorical_cols\n",
    "    dict_cols['categorical_cols'].remove('AnimalID') # remove ids\n",
    "    dict_cols['categorical_cols'].remove('OutcomeType') # remove labels\n",
    "    dict_cols['categorical_cols'].remove('OutcomeSubtype')\n",
    "\n",
    "    # numeric columns\n",
    "    dict_cols['numerical_cols'] = numerical_cols\n",
    "\n",
    "    # id columns\n",
    "    dict_cols['id_col'] = ['AnimalID']\n",
    "\n",
    "    # label columns\n",
    "    dict_cols['label_col'] = ['OutcomeType']\n",
    "    \n",
    "    # Merge train and test\n",
    "    dict_cols['train_size'] = train.shape[0]\n",
    "    dict_cols['test_size'] = test.shape[0]\n",
    "    print 'train data size: %s' % dict_cols['train_size']\n",
    "    print 'test data size: %s' % dict_cols['test_size']\n",
    "\n",
    "    full_data = pd.concat([train[dict_cols['categorical_cols'] + dict_cols['numerical_cols'] + dict_cols['label_col']]\n",
    "                         , test[dict_cols['categorical_cols'] + dict_cols['numerical_cols']]\n",
    "                        ])\n",
    "    \n",
    "    return dict_cols, full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## function to grid search the best model\n",
    "def search_model(train_x, train_y, est, param_grid, n_jobs, cv, refit=False):\n",
    "    model = grid_search.GridSearchCV(estimator  = est, \n",
    "                                     param_grid = param_grid, \n",
    "                                     scoring = 'log_loss', \n",
    "                                     verbose = 10, \n",
    "                                     n_jobs  = n_jobs, \n",
    "                                     iid = True, # is identically distributed \n",
    "                                     refit = refit,\n",
    "                                     cv = cv)\n",
    "    # Fit Grid Search Model\n",
    "    model.fit(train_x, train_y)\n",
    "    print(\"Best score: %0.3f\" % model.best_score_)\n",
    "    print(\"Best parameters set:\", model.best_params_)\n",
    "    print(\"Scores:\", model.grid_scores_)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to plot feature importance\n",
    "def plot_feature_importance(feature_importances, feature_names):\n",
    "    ftr_imp_df = pd.DataFrame(sorted(zip(feature_names, feature_importances)\n",
    "                          , key=lambda x: x[1], reverse = False)\n",
    "                   )\n",
    "    y_pos = np.arange(ftr_imp_df.shape[0])\n",
    "\n",
    "    plt.barh(y_pos, ftr_imp_df[1], align='center', alpha=0.4)\n",
    "    plt.yticks(y_pos, ftr_imp_df[0])\n",
    "    plt.xlabel('Feature Importance')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to label encoding, and output label mapping\n",
    "def label_encoding(cols, full_data):\n",
    "    label_mapping = {}\n",
    "    for col in cols:\n",
    "        print(\"Label encoding column: %s\" % (col))\n",
    "        LBL = preprocessing.LabelEncoder()\n",
    "        LBL.fit(full_data[col])\n",
    "        if col == 'OutcomeType':\n",
    "            label_mapping = dict(zip(full_data['OutcomeType'].unique(), LBL.transform(full_data['OutcomeType'].unique())))\n",
    "#             print(\"Label mapping: %s\" % (label_mapping))\n",
    "        full_data[col] = LBL.transform(full_data[col])\n",
    "        \n",
    "    return label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to transform ages into days\n",
    "def age2days(age):\n",
    "    age = str(age)\n",
    "    if 'day' in age:\n",
    "        days = int(age.split(' ')[0])\n",
    "    if 'week' in age:\n",
    "        days= int(age.split(' ')[0])*7\n",
    "    if 'month' in age:\n",
    "        days = int(age.split(' ')[0])*30\n",
    "    if 'year' in age:\n",
    "        days = int(age.split(' ')[0])*365    \n",
    "    else:\n",
    "        days = 0\n",
    "    return days   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data finished in 0.091s\n",
      "Loading test data finished in 0.123s\n",
      "train data size: 26729\n",
      "test data size: 11456\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dict_cols, full_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data['AgeuponOutcome'] = full_data['AgeuponOutcome'].apply(age2days)\n",
    "full_data['Breed'] = full_data['Breed'].apply(lambda x: '-'.join(sorted(list(set(x.split(\"/\"))))))\n",
    "full_data['NameLength'] = full_data['Name'].apply(lambda x: len(str(x)) if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_cols['categorical_cols'].remove('AgeuponOutcome')\n",
    "dict_cols['numerical_cols'].append('AgeuponOutcome')\n",
    "dict_cols['numerical_cols'].append('NameLength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data['year'] = full_data['DateTime'].dt.year\n",
    "full_data['month'] = full_data['DateTime'].dt.month\n",
    "full_data['day'] = full_data['DateTime'].dt.day\n",
    "full_data['weekday'] = full_data['DateTime'].dt.dayofweek\n",
    "full_data['weekyear'] = full_data['DateTime'].dt.weekofyear\n",
    "full_data['hour'] = full_data['DateTime'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_cols['numerical_cols'].append('year')\n",
    "dict_cols['numerical_cols'].append('month')\n",
    "dict_cols['numerical_cols'].append('day')\n",
    "dict_cols['numerical_cols'].append('weekday')\n",
    "dict_cols['numerical_cols'].append('weekyear')\n",
    "dict_cols['numerical_cols'].append('hour') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data[\"DateTime\"] = full_data[\"DateTime\"].apply(lambda x:str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoding column: Name\n",
      "Label encoding column: AnimalType\n",
      "Label encoding column: SexuponOutcome\n",
      "Label encoding column: Breed\n",
      "Label encoding column: Color\n",
      "Label encoding column: DateTime\n",
      "Label encoding column: OutcomeType\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{nan: 0,\n",
       " 'Adoption': 1,\n",
       " 'Died': 2,\n",
       " 'Euthanasia': 3,\n",
       " 'Return_to_owner': 4,\n",
       " 'Transfer': 5}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoding(dict_cols['categorical_cols'] + dict_cols['label_col'], full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgeuponOutcome    int64\n",
       "AnimalType        int64\n",
       "Breed             int64\n",
       "Color             int64\n",
       "DateTime          int64\n",
       "Name              int64\n",
       "OutcomeType       int64\n",
       "SexuponOutcome    int64\n",
       "NameLength        int64\n",
       "year              int64\n",
       "month             int64\n",
       "day               int64\n",
       "weekday           int64\n",
       "weekyear          int64\n",
       "hour              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = full_data[:dict_cols['train_size']][dict_cols['categorical_cols'] + dict_cols['numerical_cols']].fillna(-999).values\n",
    "train_y = full_data[:dict_cols['train_size']][dict_cols['label_col']].fillna(-999).values.reshape(dict_cols['train_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost tuning\n",
    "###### Here we are using a wrapped functions instead of the XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_train(trainX,trainY,params):\n",
    "#XGBoost wrapper - to enable early stopping and missing value\n",
    "    plst = list(params.items())\n",
    "    offset = int(trainX.shape[0]*0.08)\n",
    "    num_rounds = 10000\n",
    "    xgtrain = xgb.DMatrix(trainX[offset:,:], label=trainY[offset:], missing=-999)\n",
    "    xgval = xgb.DMatrix(trainX[:offset,:], label=trainY[:offset], missing=-999)\n",
    "\n",
    "    #train using early stopping and predict\n",
    "    watchlist = [(xgtrain, 'train'),(xgval, 'val')]\n",
    "    model = xgb.train(params=plst, dtrain=xgtrain, num_boost_round=num_rounds, evals=watchlist,  early_stopping_rounds=100)\n",
    "    print (\"Best score:\", model.best_score)\n",
    "    print (\"Best iteration:\", model.best_iteration)\n",
    "    return model\n",
    "\n",
    "def xgb_pred(model,testX,params):\n",
    "#XGBoost wrapper \n",
    "    xgtest = xgb.DMatrix(testX, missing=-999)\n",
    "    preds = model.predict(xgtest,ntree_limit=model.best_iteration)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - choose a relatively larger learning rate(0.02) then use early stopping for optimal rounds\n",
    "###### Initial parameters (works well for most cases)\n",
    "\n",
    "  learning rate: 0.02\n",
    "  \n",
    "  max_depth: 6\n",
    "  \n",
    "  \n",
    "  min_child_weight: 1\n",
    "  \n",
    "  \n",
    "  colsample_bytree: 0.7\n",
    "  \n",
    "  \n",
    "  subsample : 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until val error hasn't decreased in 100 rounds.\n",
      "[0]\ttrain-mlogloss:1.767655\tval-mlogloss:1.768356\n",
      "[1]\ttrain-mlogloss:1.744993\tval-mlogloss:1.746305\n",
      "[2]\ttrain-mlogloss:1.724192\tval-mlogloss:1.726164\n",
      "[3]\ttrain-mlogloss:1.702380\tval-mlogloss:1.704886\n",
      "[4]\ttrain-mlogloss:1.681083\tval-mlogloss:1.684289\n",
      "[5]\ttrain-mlogloss:1.658807\tval-mlogloss:1.662463\n",
      "[6]\ttrain-mlogloss:1.637838\tval-mlogloss:1.641897\n",
      "[7]\ttrain-mlogloss:1.620651\tval-mlogloss:1.625250\n",
      "[8]\ttrain-mlogloss:1.602389\tval-mlogloss:1.607617\n",
      "[9]\ttrain-mlogloss:1.584257\tval-mlogloss:1.590029\n",
      "[10]\ttrain-mlogloss:1.565539\tval-mlogloss:1.571700\n",
      "[11]\ttrain-mlogloss:1.548284\tval-mlogloss:1.554888\n",
      "[12]\ttrain-mlogloss:1.532859\tval-mlogloss:1.540049\n",
      "[13]\ttrain-mlogloss:1.517433\tval-mlogloss:1.525140\n",
      "[14]\ttrain-mlogloss:1.501511\tval-mlogloss:1.509682\n",
      "[15]\ttrain-mlogloss:1.487196\tval-mlogloss:1.495976\n",
      "[16]\ttrain-mlogloss:1.473337\tval-mlogloss:1.482625\n",
      "[17]\ttrain-mlogloss:1.458890\tval-mlogloss:1.468683\n",
      "[18]\ttrain-mlogloss:1.444728\tval-mlogloss:1.454868\n",
      "[19]\ttrain-mlogloss:1.430631\tval-mlogloss:1.441131\n",
      "[20]\ttrain-mlogloss:1.418198\tval-mlogloss:1.429166\n",
      "[21]\ttrain-mlogloss:1.405153\tval-mlogloss:1.416396\n",
      "[22]\ttrain-mlogloss:1.392168\tval-mlogloss:1.403805\n",
      "[23]\ttrain-mlogloss:1.380183\tval-mlogloss:1.392379\n",
      "[24]\ttrain-mlogloss:1.369176\tval-mlogloss:1.381849\n",
      "[25]\ttrain-mlogloss:1.358336\tval-mlogloss:1.371598\n",
      "[26]\ttrain-mlogloss:1.346617\tval-mlogloss:1.360232\n",
      "[27]\ttrain-mlogloss:1.336129\tval-mlogloss:1.350269\n",
      "[28]\ttrain-mlogloss:1.324987\tval-mlogloss:1.339503\n",
      "[29]\ttrain-mlogloss:1.314041\tval-mlogloss:1.328903\n",
      "[30]\ttrain-mlogloss:1.303394\tval-mlogloss:1.318485\n",
      "[31]\ttrain-mlogloss:1.294269\tval-mlogloss:1.309900\n",
      "[32]\ttrain-mlogloss:1.284791\tval-mlogloss:1.300972\n",
      "[33]\ttrain-mlogloss:1.274415\tval-mlogloss:1.290926\n",
      "[34]\ttrain-mlogloss:1.265529\tval-mlogloss:1.282459\n",
      "[35]\ttrain-mlogloss:1.256833\tval-mlogloss:1.274271\n",
      "[36]\ttrain-mlogloss:1.248485\tval-mlogloss:1.266343\n",
      "[37]\ttrain-mlogloss:1.239329\tval-mlogloss:1.257655\n",
      "[38]\ttrain-mlogloss:1.231087\tval-mlogloss:1.249700\n",
      "[39]\ttrain-mlogloss:1.223216\tval-mlogloss:1.242265\n",
      "[40]\ttrain-mlogloss:1.214392\tval-mlogloss:1.233830\n",
      "[41]\ttrain-mlogloss:1.206061\tval-mlogloss:1.225977\n",
      "[42]\ttrain-mlogloss:1.197892\tval-mlogloss:1.218240\n",
      "[43]\ttrain-mlogloss:1.189540\tval-mlogloss:1.210141\n",
      "[44]\ttrain-mlogloss:1.182848\tval-mlogloss:1.203948\n",
      "[45]\ttrain-mlogloss:1.175112\tval-mlogloss:1.196546\n",
      "[46]\ttrain-mlogloss:1.168266\tval-mlogloss:1.190078\n",
      "[47]\ttrain-mlogloss:1.161321\tval-mlogloss:1.183417\n",
      "[48]\ttrain-mlogloss:1.154253\tval-mlogloss:1.176730\n",
      "[49]\ttrain-mlogloss:1.147244\tval-mlogloss:1.169988\n",
      "[50]\ttrain-mlogloss:1.140222\tval-mlogloss:1.163356\n",
      "[51]\ttrain-mlogloss:1.133442\tval-mlogloss:1.156919\n",
      "[52]\ttrain-mlogloss:1.127440\tval-mlogloss:1.151399\n",
      "[53]\ttrain-mlogloss:1.121154\tval-mlogloss:1.145437\n",
      "[54]\ttrain-mlogloss:1.114790\tval-mlogloss:1.139427\n",
      "[55]\ttrain-mlogloss:1.109189\tval-mlogloss:1.134195\n",
      "[56]\ttrain-mlogloss:1.102985\tval-mlogloss:1.128374\n",
      "[57]\ttrain-mlogloss:1.097304\tval-mlogloss:1.123071\n",
      "[58]\ttrain-mlogloss:1.091842\tval-mlogloss:1.117964\n",
      "[59]\ttrain-mlogloss:1.086166\tval-mlogloss:1.112646\n",
      "[60]\ttrain-mlogloss:1.080230\tval-mlogloss:1.106925\n",
      "[61]\ttrain-mlogloss:1.074627\tval-mlogloss:1.101658\n",
      "[62]\ttrain-mlogloss:1.069399\tval-mlogloss:1.096821\n",
      "[63]\ttrain-mlogloss:1.064506\tval-mlogloss:1.092367\n",
      "[64]\ttrain-mlogloss:1.059134\tval-mlogloss:1.087247\n",
      "[65]\ttrain-mlogloss:1.054511\tval-mlogloss:1.082926\n",
      "[66]\ttrain-mlogloss:1.049267\tval-mlogloss:1.078101\n",
      "[67]\ttrain-mlogloss:1.044386\tval-mlogloss:1.073618\n",
      "[68]\ttrain-mlogloss:1.039913\tval-mlogloss:1.069446\n",
      "[69]\ttrain-mlogloss:1.035583\tval-mlogloss:1.065602\n",
      "[70]\ttrain-mlogloss:1.031299\tval-mlogloss:1.061743\n",
      "[71]\ttrain-mlogloss:1.026425\tval-mlogloss:1.057141\n",
      "[72]\ttrain-mlogloss:1.021988\tval-mlogloss:1.053105\n",
      "[73]\ttrain-mlogloss:1.017408\tval-mlogloss:1.048905\n",
      "[74]\ttrain-mlogloss:1.012802\tval-mlogloss:1.044632\n",
      "[75]\ttrain-mlogloss:1.008854\tval-mlogloss:1.040965\n",
      "[76]\ttrain-mlogloss:1.004797\tval-mlogloss:1.037345\n",
      "[77]\ttrain-mlogloss:1.000227\tval-mlogloss:1.033126\n",
      "[78]\ttrain-mlogloss:0.996460\tval-mlogloss:1.029745\n",
      "[79]\ttrain-mlogloss:0.992789\tval-mlogloss:1.026396\n",
      "[80]\ttrain-mlogloss:0.989072\tval-mlogloss:1.023064\n",
      "[81]\ttrain-mlogloss:0.985436\tval-mlogloss:1.019722\n",
      "[82]\ttrain-mlogloss:0.981424\tval-mlogloss:1.016062\n",
      "[83]\ttrain-mlogloss:0.977453\tval-mlogloss:1.012434\n",
      "[84]\ttrain-mlogloss:0.973967\tval-mlogloss:1.009370\n",
      "[85]\ttrain-mlogloss:0.970663\tval-mlogloss:1.006497\n",
      "[86]\ttrain-mlogloss:0.967054\tval-mlogloss:1.003205\n",
      "[87]\ttrain-mlogloss:0.963826\tval-mlogloss:1.000342\n",
      "[88]\ttrain-mlogloss:0.960472\tval-mlogloss:0.997240\n",
      "[89]\ttrain-mlogloss:0.957045\tval-mlogloss:0.994130\n",
      "[90]\ttrain-mlogloss:0.953924\tval-mlogloss:0.991432\n",
      "[91]\ttrain-mlogloss:0.950318\tval-mlogloss:0.988105\n",
      "[92]\ttrain-mlogloss:0.947287\tval-mlogloss:0.985414\n",
      "[93]\ttrain-mlogloss:0.944151\tval-mlogloss:0.982619\n",
      "[94]\ttrain-mlogloss:0.940938\tval-mlogloss:0.979752\n",
      "[95]\ttrain-mlogloss:0.937578\tval-mlogloss:0.976671\n",
      "[96]\ttrain-mlogloss:0.934698\tval-mlogloss:0.974123\n",
      "[97]\ttrain-mlogloss:0.931578\tval-mlogloss:0.971336\n",
      "[98]\ttrain-mlogloss:0.928352\tval-mlogloss:0.968372\n",
      "[99]\ttrain-mlogloss:0.925618\tval-mlogloss:0.965992\n",
      "[100]\ttrain-mlogloss:0.922676\tval-mlogloss:0.963424\n",
      "[101]\ttrain-mlogloss:0.920102\tval-mlogloss:0.961229\n",
      "[102]\ttrain-mlogloss:0.917177\tval-mlogloss:0.958638\n",
      "[103]\ttrain-mlogloss:0.914542\tval-mlogloss:0.956368\n",
      "[104]\ttrain-mlogloss:0.912041\tval-mlogloss:0.954256\n",
      "[105]\ttrain-mlogloss:0.909278\tval-mlogloss:0.951775\n",
      "[106]\ttrain-mlogloss:0.906587\tval-mlogloss:0.949328\n",
      "[107]\ttrain-mlogloss:0.904044\tval-mlogloss:0.947067\n",
      "[108]\ttrain-mlogloss:0.901179\tval-mlogloss:0.944525\n",
      "[109]\ttrain-mlogloss:0.898471\tval-mlogloss:0.942112\n",
      "[110]\ttrain-mlogloss:0.895802\tval-mlogloss:0.939810\n",
      "[111]\ttrain-mlogloss:0.893303\tval-mlogloss:0.937557\n",
      "[112]\ttrain-mlogloss:0.891001\tval-mlogloss:0.935640\n",
      "[113]\ttrain-mlogloss:0.888517\tval-mlogloss:0.933447\n",
      "[114]\ttrain-mlogloss:0.886010\tval-mlogloss:0.931202\n",
      "[115]\ttrain-mlogloss:0.883702\tval-mlogloss:0.929204\n",
      "[116]\ttrain-mlogloss:0.881274\tval-mlogloss:0.927083\n",
      "[117]\ttrain-mlogloss:0.879067\tval-mlogloss:0.925270\n",
      "[118]\ttrain-mlogloss:0.876723\tval-mlogloss:0.923207\n",
      "[119]\ttrain-mlogloss:0.874347\tval-mlogloss:0.921153\n",
      "[120]\ttrain-mlogloss:0.872270\tval-mlogloss:0.919402\n",
      "[121]\ttrain-mlogloss:0.870075\tval-mlogloss:0.917487\n",
      "[122]\ttrain-mlogloss:0.867943\tval-mlogloss:0.915699\n",
      "[123]\ttrain-mlogloss:0.865949\tval-mlogloss:0.914082\n",
      "[124]\ttrain-mlogloss:0.863989\tval-mlogloss:0.912495\n",
      "[125]\ttrain-mlogloss:0.861999\tval-mlogloss:0.910819\n",
      "[126]\ttrain-mlogloss:0.860050\tval-mlogloss:0.909180\n",
      "[127]\ttrain-mlogloss:0.858091\tval-mlogloss:0.907564\n",
      "[128]\ttrain-mlogloss:0.856012\tval-mlogloss:0.905879\n",
      "[129]\ttrain-mlogloss:0.853991\tval-mlogloss:0.904174\n",
      "[130]\ttrain-mlogloss:0.852172\tval-mlogloss:0.902811\n",
      "[131]\ttrain-mlogloss:0.850316\tval-mlogloss:0.901398\n",
      "[132]\ttrain-mlogloss:0.848506\tval-mlogloss:0.900005\n",
      "[133]\ttrain-mlogloss:0.846728\tval-mlogloss:0.898624\n",
      "[134]\ttrain-mlogloss:0.845016\tval-mlogloss:0.897339\n",
      "[135]\ttrain-mlogloss:0.843186\tval-mlogloss:0.895790\n",
      "[136]\ttrain-mlogloss:0.841416\tval-mlogloss:0.894274\n",
      "[137]\ttrain-mlogloss:0.839785\tval-mlogloss:0.893016\n",
      "[138]\ttrain-mlogloss:0.838030\tval-mlogloss:0.891643\n",
      "[139]\ttrain-mlogloss:0.836284\tval-mlogloss:0.890277\n",
      "[140]\ttrain-mlogloss:0.834721\tval-mlogloss:0.889156\n",
      "[141]\ttrain-mlogloss:0.833233\tval-mlogloss:0.887906\n",
      "[142]\ttrain-mlogloss:0.831656\tval-mlogloss:0.886595\n",
      "[143]\ttrain-mlogloss:0.830101\tval-mlogloss:0.885324\n",
      "[144]\ttrain-mlogloss:0.828400\tval-mlogloss:0.883941\n",
      "[145]\ttrain-mlogloss:0.826705\tval-mlogloss:0.882688\n",
      "[146]\ttrain-mlogloss:0.825055\tval-mlogloss:0.881299\n",
      "[147]\ttrain-mlogloss:0.823602\tval-mlogloss:0.880131\n",
      "[148]\ttrain-mlogloss:0.822155\tval-mlogloss:0.878948\n",
      "[149]\ttrain-mlogloss:0.820668\tval-mlogloss:0.877802\n",
      "[150]\ttrain-mlogloss:0.819122\tval-mlogloss:0.876476\n",
      "[151]\ttrain-mlogloss:0.817606\tval-mlogloss:0.875371\n",
      "[152]\ttrain-mlogloss:0.816213\tval-mlogloss:0.874405\n",
      "[153]\ttrain-mlogloss:0.814818\tval-mlogloss:0.873383\n",
      "[154]\ttrain-mlogloss:0.813452\tval-mlogloss:0.872370\n",
      "[155]\ttrain-mlogloss:0.812036\tval-mlogloss:0.871176\n",
      "[156]\ttrain-mlogloss:0.810742\tval-mlogloss:0.870246\n",
      "[157]\ttrain-mlogloss:0.809283\tval-mlogloss:0.869126\n",
      "[158]\ttrain-mlogloss:0.807925\tval-mlogloss:0.868025\n",
      "[159]\ttrain-mlogloss:0.806613\tval-mlogloss:0.867085\n",
      "[160]\ttrain-mlogloss:0.805288\tval-mlogloss:0.866090\n",
      "[161]\ttrain-mlogloss:0.803966\tval-mlogloss:0.865137\n",
      "[162]\ttrain-mlogloss:0.802621\tval-mlogloss:0.864088\n",
      "[163]\ttrain-mlogloss:0.801286\tval-mlogloss:0.863018\n",
      "[164]\ttrain-mlogloss:0.800026\tval-mlogloss:0.862219\n",
      "[165]\ttrain-mlogloss:0.798819\tval-mlogloss:0.861349\n",
      "[166]\ttrain-mlogloss:0.797596\tval-mlogloss:0.860531\n",
      "[167]\ttrain-mlogloss:0.796303\tval-mlogloss:0.859559\n",
      "[168]\ttrain-mlogloss:0.795016\tval-mlogloss:0.858597\n",
      "[169]\ttrain-mlogloss:0.793756\tval-mlogloss:0.857649\n",
      "[170]\ttrain-mlogloss:0.792557\tval-mlogloss:0.856900\n",
      "[171]\ttrain-mlogloss:0.791456\tval-mlogloss:0.856103\n",
      "[172]\ttrain-mlogloss:0.790357\tval-mlogloss:0.855386\n",
      "[173]\ttrain-mlogloss:0.789143\tval-mlogloss:0.854539\n",
      "[174]\ttrain-mlogloss:0.787954\tval-mlogloss:0.853618\n",
      "[175]\ttrain-mlogloss:0.786847\tval-mlogloss:0.852846\n",
      "[176]\ttrain-mlogloss:0.785721\tval-mlogloss:0.852016\n",
      "[177]\ttrain-mlogloss:0.784609\tval-mlogloss:0.851232\n",
      "[178]\ttrain-mlogloss:0.783492\tval-mlogloss:0.850433\n",
      "[179]\ttrain-mlogloss:0.782271\tval-mlogloss:0.849502\n",
      "[180]\ttrain-mlogloss:0.781232\tval-mlogloss:0.848755\n",
      "[181]\ttrain-mlogloss:0.780177\tval-mlogloss:0.848039\n",
      "[182]\ttrain-mlogloss:0.779072\tval-mlogloss:0.847185\n",
      "[183]\ttrain-mlogloss:0.778030\tval-mlogloss:0.846459\n",
      "[184]\ttrain-mlogloss:0.777015\tval-mlogloss:0.845835\n",
      "[185]\ttrain-mlogloss:0.776060\tval-mlogloss:0.845139\n",
      "[186]\ttrain-mlogloss:0.775014\tval-mlogloss:0.844582\n",
      "[187]\ttrain-mlogloss:0.774000\tval-mlogloss:0.843904\n",
      "[188]\ttrain-mlogloss:0.773074\tval-mlogloss:0.843361\n",
      "[189]\ttrain-mlogloss:0.771994\tval-mlogloss:0.842557\n",
      "[190]\ttrain-mlogloss:0.771039\tval-mlogloss:0.841899\n",
      "[191]\ttrain-mlogloss:0.770073\tval-mlogloss:0.841210\n",
      "[192]\ttrain-mlogloss:0.769172\tval-mlogloss:0.840620\n",
      "[193]\ttrain-mlogloss:0.768178\tval-mlogloss:0.839882\n",
      "[194]\ttrain-mlogloss:0.767175\tval-mlogloss:0.839263\n",
      "[195]\ttrain-mlogloss:0.766302\tval-mlogloss:0.838782\n",
      "[196]\ttrain-mlogloss:0.765302\tval-mlogloss:0.838177\n",
      "[197]\ttrain-mlogloss:0.764342\tval-mlogloss:0.837517\n",
      "[198]\ttrain-mlogloss:0.763353\tval-mlogloss:0.836869\n",
      "[199]\ttrain-mlogloss:0.762552\tval-mlogloss:0.836400\n",
      "[200]\ttrain-mlogloss:0.761709\tval-mlogloss:0.835855\n",
      "[201]\ttrain-mlogloss:0.760777\tval-mlogloss:0.835271\n",
      "[202]\ttrain-mlogloss:0.759932\tval-mlogloss:0.834802\n",
      "[203]\ttrain-mlogloss:0.759075\tval-mlogloss:0.834371\n",
      "[204]\ttrain-mlogloss:0.758136\tval-mlogloss:0.833679\n",
      "[205]\ttrain-mlogloss:0.757233\tval-mlogloss:0.833077\n",
      "[206]\ttrain-mlogloss:0.756383\tval-mlogloss:0.832633\n",
      "[207]\ttrain-mlogloss:0.755549\tval-mlogloss:0.832105\n",
      "[208]\ttrain-mlogloss:0.754682\tval-mlogloss:0.831605\n",
      "[209]\ttrain-mlogloss:0.753913\tval-mlogloss:0.831179\n",
      "[210]\ttrain-mlogloss:0.753071\tval-mlogloss:0.830761\n",
      "[211]\ttrain-mlogloss:0.752233\tval-mlogloss:0.830259\n",
      "[212]\ttrain-mlogloss:0.751482\tval-mlogloss:0.829922\n",
      "[213]\ttrain-mlogloss:0.750679\tval-mlogloss:0.829394\n",
      "[214]\ttrain-mlogloss:0.749877\tval-mlogloss:0.829011\n",
      "[215]\ttrain-mlogloss:0.749129\tval-mlogloss:0.828554\n",
      "[216]\ttrain-mlogloss:0.748337\tval-mlogloss:0.828125\n",
      "[217]\ttrain-mlogloss:0.747664\tval-mlogloss:0.827783\n",
      "[218]\ttrain-mlogloss:0.746946\tval-mlogloss:0.827275\n",
      "[219]\ttrain-mlogloss:0.746225\tval-mlogloss:0.826853\n",
      "[220]\ttrain-mlogloss:0.745450\tval-mlogloss:0.826348\n",
      "[221]\ttrain-mlogloss:0.744790\tval-mlogloss:0.825998\n",
      "[222]\ttrain-mlogloss:0.744078\tval-mlogloss:0.825556\n",
      "[223]\ttrain-mlogloss:0.743353\tval-mlogloss:0.825135\n",
      "[224]\ttrain-mlogloss:0.742622\tval-mlogloss:0.824667\n",
      "[225]\ttrain-mlogloss:0.741797\tval-mlogloss:0.824138\n",
      "[226]\ttrain-mlogloss:0.741151\tval-mlogloss:0.823805\n",
      "[227]\ttrain-mlogloss:0.740432\tval-mlogloss:0.823362\n",
      "[228]\ttrain-mlogloss:0.739749\tval-mlogloss:0.822944\n",
      "[229]\ttrain-mlogloss:0.738986\tval-mlogloss:0.822467\n",
      "[230]\ttrain-mlogloss:0.738301\tval-mlogloss:0.822072\n",
      "[231]\ttrain-mlogloss:0.737605\tval-mlogloss:0.821694\n",
      "[232]\ttrain-mlogloss:0.736923\tval-mlogloss:0.821304\n",
      "[233]\ttrain-mlogloss:0.736182\tval-mlogloss:0.820863\n",
      "[234]\ttrain-mlogloss:0.735515\tval-mlogloss:0.820554\n",
      "[235]\ttrain-mlogloss:0.734770\tval-mlogloss:0.820169\n",
      "[236]\ttrain-mlogloss:0.734129\tval-mlogloss:0.819766\n",
      "[237]\ttrain-mlogloss:0.733477\tval-mlogloss:0.819415\n",
      "[238]\ttrain-mlogloss:0.732803\tval-mlogloss:0.819077\n",
      "[239]\ttrain-mlogloss:0.732173\tval-mlogloss:0.818752\n",
      "[240]\ttrain-mlogloss:0.731576\tval-mlogloss:0.818503\n",
      "[241]\ttrain-mlogloss:0.730852\tval-mlogloss:0.818189\n",
      "[242]\ttrain-mlogloss:0.730229\tval-mlogloss:0.817902\n",
      "[243]\ttrain-mlogloss:0.729594\tval-mlogloss:0.817567\n",
      "[244]\ttrain-mlogloss:0.728951\tval-mlogloss:0.817225\n",
      "[245]\ttrain-mlogloss:0.728300\tval-mlogloss:0.816864\n",
      "[246]\ttrain-mlogloss:0.727660\tval-mlogloss:0.816569\n",
      "[247]\ttrain-mlogloss:0.726992\tval-mlogloss:0.816223\n",
      "[248]\ttrain-mlogloss:0.726418\tval-mlogloss:0.815963\n",
      "[249]\ttrain-mlogloss:0.725769\tval-mlogloss:0.815714\n",
      "[250]\ttrain-mlogloss:0.725172\tval-mlogloss:0.815405\n",
      "[251]\ttrain-mlogloss:0.724529\tval-mlogloss:0.814996\n",
      "[252]\ttrain-mlogloss:0.723955\tval-mlogloss:0.814698\n",
      "[253]\ttrain-mlogloss:0.723306\tval-mlogloss:0.814358\n",
      "[254]\ttrain-mlogloss:0.722768\tval-mlogloss:0.814149\n",
      "[255]\ttrain-mlogloss:0.722165\tval-mlogloss:0.813892\n",
      "[256]\ttrain-mlogloss:0.721549\tval-mlogloss:0.813587\n",
      "[257]\ttrain-mlogloss:0.720965\tval-mlogloss:0.813252\n",
      "[258]\ttrain-mlogloss:0.720358\tval-mlogloss:0.812803\n",
      "[259]\ttrain-mlogloss:0.719766\tval-mlogloss:0.812486\n",
      "[260]\ttrain-mlogloss:0.719121\tval-mlogloss:0.812182\n",
      "[261]\ttrain-mlogloss:0.718553\tval-mlogloss:0.811844\n",
      "[262]\ttrain-mlogloss:0.717947\tval-mlogloss:0.811546\n",
      "[263]\ttrain-mlogloss:0.717369\tval-mlogloss:0.811226\n",
      "[264]\ttrain-mlogloss:0.716846\tval-mlogloss:0.810934\n",
      "[265]\ttrain-mlogloss:0.716315\tval-mlogloss:0.810711\n",
      "[266]\ttrain-mlogloss:0.715755\tval-mlogloss:0.810463\n",
      "[267]\ttrain-mlogloss:0.715274\tval-mlogloss:0.810213\n",
      "[268]\ttrain-mlogloss:0.714726\tval-mlogloss:0.809883\n",
      "[269]\ttrain-mlogloss:0.714182\tval-mlogloss:0.809679\n",
      "[270]\ttrain-mlogloss:0.713672\tval-mlogloss:0.809496\n",
      "[271]\ttrain-mlogloss:0.713147\tval-mlogloss:0.809345\n",
      "[272]\ttrain-mlogloss:0.712629\tval-mlogloss:0.809136\n",
      "[273]\ttrain-mlogloss:0.712148\tval-mlogloss:0.808941\n",
      "[274]\ttrain-mlogloss:0.711615\tval-mlogloss:0.808700\n",
      "[275]\ttrain-mlogloss:0.711054\tval-mlogloss:0.808463\n",
      "[276]\ttrain-mlogloss:0.710473\tval-mlogloss:0.808239\n",
      "[277]\ttrain-mlogloss:0.709963\tval-mlogloss:0.808029\n",
      "[278]\ttrain-mlogloss:0.709472\tval-mlogloss:0.807808\n",
      "[279]\ttrain-mlogloss:0.708970\tval-mlogloss:0.807624\n",
      "[280]\ttrain-mlogloss:0.708439\tval-mlogloss:0.807341\n",
      "[281]\ttrain-mlogloss:0.707912\tval-mlogloss:0.806987\n",
      "[282]\ttrain-mlogloss:0.707470\tval-mlogloss:0.806828\n",
      "[283]\ttrain-mlogloss:0.706998\tval-mlogloss:0.806578\n",
      "[284]\ttrain-mlogloss:0.706528\tval-mlogloss:0.806406\n",
      "[285]\ttrain-mlogloss:0.706052\tval-mlogloss:0.806194\n",
      "[286]\ttrain-mlogloss:0.705524\tval-mlogloss:0.805968\n",
      "[287]\ttrain-mlogloss:0.705084\tval-mlogloss:0.805822\n",
      "[288]\ttrain-mlogloss:0.704620\tval-mlogloss:0.805619\n",
      "[289]\ttrain-mlogloss:0.704201\tval-mlogloss:0.805454\n",
      "[290]\ttrain-mlogloss:0.703698\tval-mlogloss:0.805219\n",
      "[291]\ttrain-mlogloss:0.703293\tval-mlogloss:0.805038\n",
      "[292]\ttrain-mlogloss:0.702766\tval-mlogloss:0.804849\n",
      "[293]\ttrain-mlogloss:0.702309\tval-mlogloss:0.804669\n",
      "[294]\ttrain-mlogloss:0.701868\tval-mlogloss:0.804497\n",
      "[295]\ttrain-mlogloss:0.701341\tval-mlogloss:0.804300\n",
      "[296]\ttrain-mlogloss:0.700837\tval-mlogloss:0.804097\n",
      "[297]\ttrain-mlogloss:0.700346\tval-mlogloss:0.803956\n",
      "[298]\ttrain-mlogloss:0.699856\tval-mlogloss:0.803708\n",
      "[299]\ttrain-mlogloss:0.699376\tval-mlogloss:0.803478\n",
      "[300]\ttrain-mlogloss:0.698895\tval-mlogloss:0.803220\n",
      "[301]\ttrain-mlogloss:0.698421\tval-mlogloss:0.803123\n",
      "[302]\ttrain-mlogloss:0.697913\tval-mlogloss:0.802979\n",
      "[303]\ttrain-mlogloss:0.697444\tval-mlogloss:0.802859\n",
      "[304]\ttrain-mlogloss:0.696969\tval-mlogloss:0.802650\n",
      "[305]\ttrain-mlogloss:0.696573\tval-mlogloss:0.802487\n",
      "[306]\ttrain-mlogloss:0.696136\tval-mlogloss:0.802333\n",
      "[307]\ttrain-mlogloss:0.695641\tval-mlogloss:0.802113\n",
      "[308]\ttrain-mlogloss:0.695187\tval-mlogloss:0.801971\n",
      "[309]\ttrain-mlogloss:0.694757\tval-mlogloss:0.801800\n",
      "[310]\ttrain-mlogloss:0.694251\tval-mlogloss:0.801584\n",
      "[311]\ttrain-mlogloss:0.693824\tval-mlogloss:0.801412\n",
      "[312]\ttrain-mlogloss:0.693461\tval-mlogloss:0.801233\n",
      "[313]\ttrain-mlogloss:0.693011\tval-mlogloss:0.801048\n",
      "[314]\ttrain-mlogloss:0.692570\tval-mlogloss:0.800910\n",
      "[315]\ttrain-mlogloss:0.692134\tval-mlogloss:0.800744\n",
      "[316]\ttrain-mlogloss:0.691709\tval-mlogloss:0.800637\n",
      "[317]\ttrain-mlogloss:0.691272\tval-mlogloss:0.800530\n",
      "[318]\ttrain-mlogloss:0.690835\tval-mlogloss:0.800390\n",
      "[319]\ttrain-mlogloss:0.690403\tval-mlogloss:0.800234\n",
      "[320]\ttrain-mlogloss:0.689977\tval-mlogloss:0.800116\n",
      "[321]\ttrain-mlogloss:0.689555\tval-mlogloss:0.800026\n",
      "[322]\ttrain-mlogloss:0.689093\tval-mlogloss:0.799900\n",
      "[323]\ttrain-mlogloss:0.688741\tval-mlogloss:0.799748\n",
      "[324]\ttrain-mlogloss:0.688268\tval-mlogloss:0.799538\n",
      "[325]\ttrain-mlogloss:0.687890\tval-mlogloss:0.799363\n",
      "[326]\ttrain-mlogloss:0.687504\tval-mlogloss:0.799264\n",
      "[327]\ttrain-mlogloss:0.687031\tval-mlogloss:0.799064\n",
      "[328]\ttrain-mlogloss:0.686623\tval-mlogloss:0.798817\n",
      "[329]\ttrain-mlogloss:0.686288\tval-mlogloss:0.798755\n",
      "[330]\ttrain-mlogloss:0.685895\tval-mlogloss:0.798604\n",
      "[331]\ttrain-mlogloss:0.685487\tval-mlogloss:0.798393\n",
      "[332]\ttrain-mlogloss:0.685079\tval-mlogloss:0.798290\n",
      "[333]\ttrain-mlogloss:0.684695\tval-mlogloss:0.798160\n",
      "[334]\ttrain-mlogloss:0.684375\tval-mlogloss:0.798054\n",
      "[335]\ttrain-mlogloss:0.684066\tval-mlogloss:0.797994\n",
      "[336]\ttrain-mlogloss:0.683662\tval-mlogloss:0.797913\n",
      "[337]\ttrain-mlogloss:0.683296\tval-mlogloss:0.797770\n",
      "[338]\ttrain-mlogloss:0.682903\tval-mlogloss:0.797607\n",
      "[339]\ttrain-mlogloss:0.682501\tval-mlogloss:0.797506\n",
      "[340]\ttrain-mlogloss:0.682131\tval-mlogloss:0.797351\n",
      "[341]\ttrain-mlogloss:0.681770\tval-mlogloss:0.797189\n",
      "[342]\ttrain-mlogloss:0.681371\tval-mlogloss:0.797009\n",
      "[343]\ttrain-mlogloss:0.680960\tval-mlogloss:0.796836\n",
      "[344]\ttrain-mlogloss:0.680589\tval-mlogloss:0.796747\n",
      "[345]\ttrain-mlogloss:0.680216\tval-mlogloss:0.796754\n",
      "[346]\ttrain-mlogloss:0.679882\tval-mlogloss:0.796673\n",
      "[347]\ttrain-mlogloss:0.679480\tval-mlogloss:0.796512\n",
      "[348]\ttrain-mlogloss:0.679061\tval-mlogloss:0.796357\n",
      "[349]\ttrain-mlogloss:0.678683\tval-mlogloss:0.796299\n",
      "[350]\ttrain-mlogloss:0.678368\tval-mlogloss:0.796224\n",
      "[351]\ttrain-mlogloss:0.678032\tval-mlogloss:0.796141\n",
      "[352]\ttrain-mlogloss:0.677580\tval-mlogloss:0.796021\n",
      "[353]\ttrain-mlogloss:0.677247\tval-mlogloss:0.795916\n",
      "[354]\ttrain-mlogloss:0.676934\tval-mlogloss:0.795810\n",
      "[355]\ttrain-mlogloss:0.676592\tval-mlogloss:0.795737\n",
      "[356]\ttrain-mlogloss:0.676284\tval-mlogloss:0.795658\n",
      "[357]\ttrain-mlogloss:0.675943\tval-mlogloss:0.795635\n",
      "[358]\ttrain-mlogloss:0.675601\tval-mlogloss:0.795619\n",
      "[359]\ttrain-mlogloss:0.675301\tval-mlogloss:0.795516\n",
      "[360]\ttrain-mlogloss:0.674902\tval-mlogloss:0.795335\n",
      "[361]\ttrain-mlogloss:0.674556\tval-mlogloss:0.795292\n",
      "[362]\ttrain-mlogloss:0.674220\tval-mlogloss:0.795215\n",
      "[363]\ttrain-mlogloss:0.673783\tval-mlogloss:0.795105\n",
      "[364]\ttrain-mlogloss:0.673423\tval-mlogloss:0.795026\n",
      "[365]\ttrain-mlogloss:0.673027\tval-mlogloss:0.794968\n",
      "[366]\ttrain-mlogloss:0.672627\tval-mlogloss:0.794874\n",
      "[367]\ttrain-mlogloss:0.672264\tval-mlogloss:0.794791\n",
      "[368]\ttrain-mlogloss:0.671933\tval-mlogloss:0.794809\n",
      "[369]\ttrain-mlogloss:0.671528\tval-mlogloss:0.794658\n",
      "[370]\ttrain-mlogloss:0.671197\tval-mlogloss:0.794610\n",
      "[371]\ttrain-mlogloss:0.670876\tval-mlogloss:0.794488\n",
      "[372]\ttrain-mlogloss:0.670536\tval-mlogloss:0.794396\n",
      "[373]\ttrain-mlogloss:0.670235\tval-mlogloss:0.794325\n",
      "[374]\ttrain-mlogloss:0.669918\tval-mlogloss:0.794306\n",
      "[375]\ttrain-mlogloss:0.669640\tval-mlogloss:0.794210\n",
      "[376]\ttrain-mlogloss:0.669331\tval-mlogloss:0.794106\n",
      "[377]\ttrain-mlogloss:0.668969\tval-mlogloss:0.794001\n",
      "[378]\ttrain-mlogloss:0.668657\tval-mlogloss:0.793901\n",
      "[379]\ttrain-mlogloss:0.668268\tval-mlogloss:0.793733\n",
      "[380]\ttrain-mlogloss:0.667890\tval-mlogloss:0.793581\n",
      "[381]\ttrain-mlogloss:0.667529\tval-mlogloss:0.793429\n",
      "[382]\ttrain-mlogloss:0.667284\tval-mlogloss:0.793378\n",
      "[383]\ttrain-mlogloss:0.666951\tval-mlogloss:0.793314\n",
      "[384]\ttrain-mlogloss:0.666626\tval-mlogloss:0.793261\n",
      "[385]\ttrain-mlogloss:0.666261\tval-mlogloss:0.793121\n",
      "[386]\ttrain-mlogloss:0.665945\tval-mlogloss:0.793003\n",
      "[387]\ttrain-mlogloss:0.665635\tval-mlogloss:0.792995\n",
      "[388]\ttrain-mlogloss:0.665335\tval-mlogloss:0.792866\n",
      "[389]\ttrain-mlogloss:0.664954\tval-mlogloss:0.792768\n",
      "[390]\ttrain-mlogloss:0.664637\tval-mlogloss:0.792716\n",
      "[391]\ttrain-mlogloss:0.664341\tval-mlogloss:0.792640\n",
      "[392]\ttrain-mlogloss:0.664006\tval-mlogloss:0.792516\n",
      "[393]\ttrain-mlogloss:0.663724\tval-mlogloss:0.792450\n",
      "[394]\ttrain-mlogloss:0.663411\tval-mlogloss:0.792342\n",
      "[395]\ttrain-mlogloss:0.663041\tval-mlogloss:0.792257\n",
      "[396]\ttrain-mlogloss:0.662722\tval-mlogloss:0.792189\n",
      "[397]\ttrain-mlogloss:0.662462\tval-mlogloss:0.792121\n",
      "[398]\ttrain-mlogloss:0.662189\tval-mlogloss:0.792068\n",
      "[399]\ttrain-mlogloss:0.661950\tval-mlogloss:0.792012\n",
      "[400]\ttrain-mlogloss:0.661691\tval-mlogloss:0.791958\n",
      "[401]\ttrain-mlogloss:0.661313\tval-mlogloss:0.791961\n",
      "[402]\ttrain-mlogloss:0.661050\tval-mlogloss:0.791916\n",
      "[403]\ttrain-mlogloss:0.660788\tval-mlogloss:0.791864\n",
      "[404]\ttrain-mlogloss:0.660447\tval-mlogloss:0.791778\n",
      "[405]\ttrain-mlogloss:0.660147\tval-mlogloss:0.791728\n",
      "[406]\ttrain-mlogloss:0.659766\tval-mlogloss:0.791653\n",
      "[407]\ttrain-mlogloss:0.659407\tval-mlogloss:0.791493\n",
      "[408]\ttrain-mlogloss:0.659109\tval-mlogloss:0.791466\n",
      "[409]\ttrain-mlogloss:0.658781\tval-mlogloss:0.791373\n",
      "[410]\ttrain-mlogloss:0.658496\tval-mlogloss:0.791330\n",
      "[411]\ttrain-mlogloss:0.658227\tval-mlogloss:0.791274\n",
      "[412]\ttrain-mlogloss:0.657880\tval-mlogloss:0.791133\n",
      "[413]\ttrain-mlogloss:0.657584\tval-mlogloss:0.791016\n",
      "[414]\ttrain-mlogloss:0.657276\tval-mlogloss:0.790927\n",
      "[415]\ttrain-mlogloss:0.656885\tval-mlogloss:0.790872\n",
      "[416]\ttrain-mlogloss:0.656560\tval-mlogloss:0.790841\n",
      "[417]\ttrain-mlogloss:0.656249\tval-mlogloss:0.790818\n",
      "[418]\ttrain-mlogloss:0.655908\tval-mlogloss:0.790739\n",
      "[419]\ttrain-mlogloss:0.655599\tval-mlogloss:0.790629\n",
      "[420]\ttrain-mlogloss:0.655312\tval-mlogloss:0.790583\n",
      "[421]\ttrain-mlogloss:0.655091\tval-mlogloss:0.790590\n",
      "[422]\ttrain-mlogloss:0.654809\tval-mlogloss:0.790548\n",
      "[423]\ttrain-mlogloss:0.654493\tval-mlogloss:0.790533\n",
      "[424]\ttrain-mlogloss:0.654229\tval-mlogloss:0.790465\n",
      "[425]\ttrain-mlogloss:0.653915\tval-mlogloss:0.790504\n",
      "[426]\ttrain-mlogloss:0.653654\tval-mlogloss:0.790480\n",
      "[427]\ttrain-mlogloss:0.653348\tval-mlogloss:0.790426\n",
      "[428]\ttrain-mlogloss:0.653027\tval-mlogloss:0.790358\n",
      "[429]\ttrain-mlogloss:0.652737\tval-mlogloss:0.790247\n",
      "[430]\ttrain-mlogloss:0.652401\tval-mlogloss:0.790177\n",
      "[431]\ttrain-mlogloss:0.652126\tval-mlogloss:0.790147\n",
      "[432]\ttrain-mlogloss:0.651841\tval-mlogloss:0.790081\n",
      "[433]\ttrain-mlogloss:0.651552\tval-mlogloss:0.790033\n",
      "[434]\ttrain-mlogloss:0.651247\tval-mlogloss:0.790035\n",
      "[435]\ttrain-mlogloss:0.650934\tval-mlogloss:0.790038\n",
      "[436]\ttrain-mlogloss:0.650701\tval-mlogloss:0.789950\n",
      "[437]\ttrain-mlogloss:0.650397\tval-mlogloss:0.789910\n",
      "[438]\ttrain-mlogloss:0.650166\tval-mlogloss:0.789912\n",
      "[439]\ttrain-mlogloss:0.649951\tval-mlogloss:0.789907\n",
      "[440]\ttrain-mlogloss:0.649751\tval-mlogloss:0.789832\n",
      "[441]\ttrain-mlogloss:0.649418\tval-mlogloss:0.789740\n",
      "[442]\ttrain-mlogloss:0.649179\tval-mlogloss:0.789642\n",
      "[443]\ttrain-mlogloss:0.648897\tval-mlogloss:0.789625\n",
      "[444]\ttrain-mlogloss:0.648635\tval-mlogloss:0.789561\n",
      "[445]\ttrain-mlogloss:0.648355\tval-mlogloss:0.789504\n",
      "[446]\ttrain-mlogloss:0.648119\tval-mlogloss:0.789397\n",
      "[447]\ttrain-mlogloss:0.647869\tval-mlogloss:0.789368\n",
      "[448]\ttrain-mlogloss:0.647598\tval-mlogloss:0.789335\n",
      "[449]\ttrain-mlogloss:0.647328\tval-mlogloss:0.789207\n",
      "[450]\ttrain-mlogloss:0.647056\tval-mlogloss:0.789092\n",
      "[451]\ttrain-mlogloss:0.646815\tval-mlogloss:0.789110\n",
      "[452]\ttrain-mlogloss:0.646521\tval-mlogloss:0.789123\n",
      "[453]\ttrain-mlogloss:0.646251\tval-mlogloss:0.788939\n",
      "[454]\ttrain-mlogloss:0.646032\tval-mlogloss:0.788930\n",
      "[455]\ttrain-mlogloss:0.645786\tval-mlogloss:0.788907\n",
      "[456]\ttrain-mlogloss:0.645552\tval-mlogloss:0.788864\n",
      "[457]\ttrain-mlogloss:0.645285\tval-mlogloss:0.788834\n",
      "[458]\ttrain-mlogloss:0.645018\tval-mlogloss:0.788754\n",
      "[459]\ttrain-mlogloss:0.644701\tval-mlogloss:0.788716\n",
      "[460]\ttrain-mlogloss:0.644466\tval-mlogloss:0.788723\n",
      "[461]\ttrain-mlogloss:0.644183\tval-mlogloss:0.788735\n",
      "[462]\ttrain-mlogloss:0.643988\tval-mlogloss:0.788690\n",
      "[463]\ttrain-mlogloss:0.643681\tval-mlogloss:0.788663\n",
      "[464]\ttrain-mlogloss:0.643378\tval-mlogloss:0.788654\n",
      "[465]\ttrain-mlogloss:0.643101\tval-mlogloss:0.788589\n",
      "[466]\ttrain-mlogloss:0.642916\tval-mlogloss:0.788642\n",
      "[467]\ttrain-mlogloss:0.642564\tval-mlogloss:0.788629\n",
      "[468]\ttrain-mlogloss:0.642274\tval-mlogloss:0.788665\n",
      "[469]\ttrain-mlogloss:0.642042\tval-mlogloss:0.788615\n",
      "[470]\ttrain-mlogloss:0.641755\tval-mlogloss:0.788566\n",
      "[471]\ttrain-mlogloss:0.641482\tval-mlogloss:0.788545\n",
      "[472]\ttrain-mlogloss:0.641233\tval-mlogloss:0.788536\n",
      "[473]\ttrain-mlogloss:0.640929\tval-mlogloss:0.788473\n",
      "[474]\ttrain-mlogloss:0.640666\tval-mlogloss:0.788393\n",
      "[475]\ttrain-mlogloss:0.640441\tval-mlogloss:0.788319\n",
      "[476]\ttrain-mlogloss:0.640155\tval-mlogloss:0.788241\n",
      "[477]\ttrain-mlogloss:0.639876\tval-mlogloss:0.788245\n",
      "[478]\ttrain-mlogloss:0.639676\tval-mlogloss:0.788194\n",
      "[479]\ttrain-mlogloss:0.639462\tval-mlogloss:0.788171\n",
      "[480]\ttrain-mlogloss:0.639172\tval-mlogloss:0.788111\n",
      "[481]\ttrain-mlogloss:0.638872\tval-mlogloss:0.788036\n",
      "[482]\ttrain-mlogloss:0.638599\tval-mlogloss:0.788010\n",
      "[483]\ttrain-mlogloss:0.638299\tval-mlogloss:0.787922\n",
      "[484]\ttrain-mlogloss:0.638036\tval-mlogloss:0.787856\n",
      "[485]\ttrain-mlogloss:0.637818\tval-mlogloss:0.787796\n",
      "[486]\ttrain-mlogloss:0.637572\tval-mlogloss:0.787844\n",
      "[487]\ttrain-mlogloss:0.637361\tval-mlogloss:0.787779\n",
      "[488]\ttrain-mlogloss:0.636966\tval-mlogloss:0.787783\n",
      "[489]\ttrain-mlogloss:0.636694\tval-mlogloss:0.787791\n",
      "[490]\ttrain-mlogloss:0.636468\tval-mlogloss:0.787734\n",
      "[491]\ttrain-mlogloss:0.636221\tval-mlogloss:0.787643\n",
      "[492]\ttrain-mlogloss:0.635961\tval-mlogloss:0.787556\n",
      "[493]\ttrain-mlogloss:0.635739\tval-mlogloss:0.787567\n",
      "[494]\ttrain-mlogloss:0.635473\tval-mlogloss:0.787505\n",
      "[495]\ttrain-mlogloss:0.635197\tval-mlogloss:0.787443\n",
      "[496]\ttrain-mlogloss:0.634931\tval-mlogloss:0.787441\n",
      "[497]\ttrain-mlogloss:0.634635\tval-mlogloss:0.787367\n",
      "[498]\ttrain-mlogloss:0.634383\tval-mlogloss:0.787358\n",
      "[499]\ttrain-mlogloss:0.634179\tval-mlogloss:0.787359\n",
      "[500]\ttrain-mlogloss:0.633864\tval-mlogloss:0.787391\n",
      "[501]\ttrain-mlogloss:0.633644\tval-mlogloss:0.787390\n",
      "[502]\ttrain-mlogloss:0.633389\tval-mlogloss:0.787454\n",
      "[503]\ttrain-mlogloss:0.633185\tval-mlogloss:0.787421\n",
      "[504]\ttrain-mlogloss:0.632935\tval-mlogloss:0.787374\n",
      "[505]\ttrain-mlogloss:0.632692\tval-mlogloss:0.787366\n",
      "[506]\ttrain-mlogloss:0.632438\tval-mlogloss:0.787252\n",
      "[507]\ttrain-mlogloss:0.632187\tval-mlogloss:0.787195\n",
      "[508]\ttrain-mlogloss:0.631930\tval-mlogloss:0.787220\n",
      "[509]\ttrain-mlogloss:0.631728\tval-mlogloss:0.787188\n",
      "[510]\ttrain-mlogloss:0.631408\tval-mlogloss:0.787185\n",
      "[511]\ttrain-mlogloss:0.631240\tval-mlogloss:0.787156\n",
      "[512]\ttrain-mlogloss:0.631036\tval-mlogloss:0.787196\n",
      "[513]\ttrain-mlogloss:0.630796\tval-mlogloss:0.787123\n",
      "[514]\ttrain-mlogloss:0.630559\tval-mlogloss:0.787091\n",
      "[515]\ttrain-mlogloss:0.630399\tval-mlogloss:0.787080\n",
      "[516]\ttrain-mlogloss:0.630043\tval-mlogloss:0.787087\n",
      "[517]\ttrain-mlogloss:0.629859\tval-mlogloss:0.787094\n",
      "[518]\ttrain-mlogloss:0.629617\tval-mlogloss:0.787099\n",
      "[519]\ttrain-mlogloss:0.629387\tval-mlogloss:0.787054\n",
      "[520]\ttrain-mlogloss:0.629081\tval-mlogloss:0.786916\n",
      "[521]\ttrain-mlogloss:0.628766\tval-mlogloss:0.786941\n",
      "[522]\ttrain-mlogloss:0.628507\tval-mlogloss:0.786942\n",
      "[523]\ttrain-mlogloss:0.628279\tval-mlogloss:0.786941\n",
      "[524]\ttrain-mlogloss:0.628090\tval-mlogloss:0.786911\n",
      "[525]\ttrain-mlogloss:0.627844\tval-mlogloss:0.786849\n",
      "[526]\ttrain-mlogloss:0.627590\tval-mlogloss:0.786792\n",
      "[527]\ttrain-mlogloss:0.627275\tval-mlogloss:0.786689\n",
      "[528]\ttrain-mlogloss:0.626978\tval-mlogloss:0.786605\n",
      "[529]\ttrain-mlogloss:0.626755\tval-mlogloss:0.786552\n",
      "[530]\ttrain-mlogloss:0.626539\tval-mlogloss:0.786489\n",
      "[531]\ttrain-mlogloss:0.626261\tval-mlogloss:0.786514\n",
      "[532]\ttrain-mlogloss:0.626014\tval-mlogloss:0.786397\n",
      "[533]\ttrain-mlogloss:0.625767\tval-mlogloss:0.786348\n",
      "[534]\ttrain-mlogloss:0.625523\tval-mlogloss:0.786339\n",
      "[535]\ttrain-mlogloss:0.625278\tval-mlogloss:0.786364\n",
      "[536]\ttrain-mlogloss:0.625067\tval-mlogloss:0.786348\n",
      "[537]\ttrain-mlogloss:0.624858\tval-mlogloss:0.786311\n",
      "[538]\ttrain-mlogloss:0.624598\tval-mlogloss:0.786336\n",
      "[539]\ttrain-mlogloss:0.624366\tval-mlogloss:0.786308\n",
      "[540]\ttrain-mlogloss:0.624146\tval-mlogloss:0.786284\n",
      "[541]\ttrain-mlogloss:0.623972\tval-mlogloss:0.786261\n",
      "[542]\ttrain-mlogloss:0.623745\tval-mlogloss:0.786174\n",
      "[543]\ttrain-mlogloss:0.623467\tval-mlogloss:0.786123\n",
      "[544]\ttrain-mlogloss:0.623227\tval-mlogloss:0.786070\n",
      "[545]\ttrain-mlogloss:0.622936\tval-mlogloss:0.786003\n",
      "[546]\ttrain-mlogloss:0.622697\tval-mlogloss:0.786010\n",
      "[547]\ttrain-mlogloss:0.622455\tval-mlogloss:0.785973\n",
      "[548]\ttrain-mlogloss:0.622185\tval-mlogloss:0.786008\n",
      "[549]\ttrain-mlogloss:0.621965\tval-mlogloss:0.786005\n",
      "[550]\ttrain-mlogloss:0.621767\tval-mlogloss:0.785990\n",
      "[551]\ttrain-mlogloss:0.621532\tval-mlogloss:0.785936\n",
      "[552]\ttrain-mlogloss:0.621328\tval-mlogloss:0.785891\n",
      "[553]\ttrain-mlogloss:0.621018\tval-mlogloss:0.785870\n",
      "[554]\ttrain-mlogloss:0.620732\tval-mlogloss:0.785782\n",
      "[555]\ttrain-mlogloss:0.620451\tval-mlogloss:0.785786\n",
      "[556]\ttrain-mlogloss:0.620166\tval-mlogloss:0.785820\n",
      "[557]\ttrain-mlogloss:0.619845\tval-mlogloss:0.785897\n",
      "[558]\ttrain-mlogloss:0.619536\tval-mlogloss:0.785823\n",
      "[559]\ttrain-mlogloss:0.619312\tval-mlogloss:0.785847\n",
      "[560]\ttrain-mlogloss:0.619049\tval-mlogloss:0.785790\n",
      "[561]\ttrain-mlogloss:0.618851\tval-mlogloss:0.785737\n",
      "[562]\ttrain-mlogloss:0.618641\tval-mlogloss:0.785743\n",
      "[563]\ttrain-mlogloss:0.618434\tval-mlogloss:0.785710\n",
      "[564]\ttrain-mlogloss:0.618102\tval-mlogloss:0.785687\n",
      "[565]\ttrain-mlogloss:0.617845\tval-mlogloss:0.785680\n",
      "[566]\ttrain-mlogloss:0.617674\tval-mlogloss:0.785644\n",
      "[567]\ttrain-mlogloss:0.617452\tval-mlogloss:0.785641\n",
      "[568]\ttrain-mlogloss:0.617271\tval-mlogloss:0.785546\n",
      "[569]\ttrain-mlogloss:0.617021\tval-mlogloss:0.785548\n",
      "[570]\ttrain-mlogloss:0.616789\tval-mlogloss:0.785543\n",
      "[571]\ttrain-mlogloss:0.616593\tval-mlogloss:0.785580\n",
      "[572]\ttrain-mlogloss:0.616325\tval-mlogloss:0.785544\n",
      "[573]\ttrain-mlogloss:0.616153\tval-mlogloss:0.785530\n",
      "[574]\ttrain-mlogloss:0.615905\tval-mlogloss:0.785570\n",
      "[575]\ttrain-mlogloss:0.615645\tval-mlogloss:0.785522\n",
      "[576]\ttrain-mlogloss:0.615453\tval-mlogloss:0.785420\n",
      "[577]\ttrain-mlogloss:0.615167\tval-mlogloss:0.785402\n",
      "[578]\ttrain-mlogloss:0.614976\tval-mlogloss:0.785331\n",
      "[579]\ttrain-mlogloss:0.614751\tval-mlogloss:0.785259\n",
      "[580]\ttrain-mlogloss:0.614497\tval-mlogloss:0.785327\n",
      "[581]\ttrain-mlogloss:0.614298\tval-mlogloss:0.785339\n",
      "[582]\ttrain-mlogloss:0.614001\tval-mlogloss:0.785395\n",
      "[583]\ttrain-mlogloss:0.613759\tval-mlogloss:0.785385\n",
      "[584]\ttrain-mlogloss:0.613538\tval-mlogloss:0.785358\n",
      "[585]\ttrain-mlogloss:0.613253\tval-mlogloss:0.785384\n",
      "[586]\ttrain-mlogloss:0.613001\tval-mlogloss:0.785378\n",
      "[587]\ttrain-mlogloss:0.612741\tval-mlogloss:0.785377\n",
      "[588]\ttrain-mlogloss:0.612472\tval-mlogloss:0.785352\n",
      "[589]\ttrain-mlogloss:0.612300\tval-mlogloss:0.785380\n",
      "[590]\ttrain-mlogloss:0.612096\tval-mlogloss:0.785337\n",
      "[591]\ttrain-mlogloss:0.611934\tval-mlogloss:0.785231\n",
      "[592]\ttrain-mlogloss:0.611730\tval-mlogloss:0.785212\n",
      "[593]\ttrain-mlogloss:0.611580\tval-mlogloss:0.785203\n",
      "[594]\ttrain-mlogloss:0.611355\tval-mlogloss:0.785153\n",
      "[595]\ttrain-mlogloss:0.611174\tval-mlogloss:0.785142\n",
      "[596]\ttrain-mlogloss:0.610873\tval-mlogloss:0.785155\n",
      "[597]\ttrain-mlogloss:0.610701\tval-mlogloss:0.785117\n",
      "[598]\ttrain-mlogloss:0.610465\tval-mlogloss:0.785159\n",
      "[599]\ttrain-mlogloss:0.610236\tval-mlogloss:0.785064\n",
      "[600]\ttrain-mlogloss:0.610007\tval-mlogloss:0.785046\n",
      "[601]\ttrain-mlogloss:0.609778\tval-mlogloss:0.785034\n",
      "[602]\ttrain-mlogloss:0.609652\tval-mlogloss:0.785024\n",
      "[603]\ttrain-mlogloss:0.609466\tval-mlogloss:0.784968\n",
      "[604]\ttrain-mlogloss:0.609262\tval-mlogloss:0.784942\n",
      "[605]\ttrain-mlogloss:0.609133\tval-mlogloss:0.784929\n",
      "[606]\ttrain-mlogloss:0.608896\tval-mlogloss:0.784908\n",
      "[607]\ttrain-mlogloss:0.608664\tval-mlogloss:0.784933\n",
      "[608]\ttrain-mlogloss:0.608422\tval-mlogloss:0.784846\n",
      "[609]\ttrain-mlogloss:0.608223\tval-mlogloss:0.784867\n",
      "[610]\ttrain-mlogloss:0.607975\tval-mlogloss:0.784831\n",
      "[611]\ttrain-mlogloss:0.607750\tval-mlogloss:0.784804\n",
      "[612]\ttrain-mlogloss:0.607548\tval-mlogloss:0.784852\n",
      "[613]\ttrain-mlogloss:0.607364\tval-mlogloss:0.784864\n",
      "[614]\ttrain-mlogloss:0.607209\tval-mlogloss:0.784858\n",
      "[615]\ttrain-mlogloss:0.606974\tval-mlogloss:0.784898\n",
      "[616]\ttrain-mlogloss:0.606713\tval-mlogloss:0.784966\n",
      "[617]\ttrain-mlogloss:0.606530\tval-mlogloss:0.784927\n",
      "[618]\ttrain-mlogloss:0.606258\tval-mlogloss:0.784827\n",
      "[619]\ttrain-mlogloss:0.606054\tval-mlogloss:0.784849\n",
      "[620]\ttrain-mlogloss:0.605859\tval-mlogloss:0.784863\n",
      "[621]\ttrain-mlogloss:0.605638\tval-mlogloss:0.784887\n",
      "[622]\ttrain-mlogloss:0.605390\tval-mlogloss:0.784803\n",
      "[623]\ttrain-mlogloss:0.605171\tval-mlogloss:0.784793\n",
      "[624]\ttrain-mlogloss:0.604933\tval-mlogloss:0.784795\n",
      "[625]\ttrain-mlogloss:0.604799\tval-mlogloss:0.784759\n",
      "[626]\ttrain-mlogloss:0.604531\tval-mlogloss:0.784720\n",
      "[627]\ttrain-mlogloss:0.604362\tval-mlogloss:0.784713\n",
      "[628]\ttrain-mlogloss:0.604180\tval-mlogloss:0.784691\n",
      "[629]\ttrain-mlogloss:0.603955\tval-mlogloss:0.784707\n",
      "[630]\ttrain-mlogloss:0.603722\tval-mlogloss:0.784663\n",
      "[631]\ttrain-mlogloss:0.603501\tval-mlogloss:0.784610\n",
      "[632]\ttrain-mlogloss:0.603274\tval-mlogloss:0.784591\n",
      "[633]\ttrain-mlogloss:0.603152\tval-mlogloss:0.784621\n",
      "[634]\ttrain-mlogloss:0.602953\tval-mlogloss:0.784620\n",
      "[635]\ttrain-mlogloss:0.602735\tval-mlogloss:0.784682\n",
      "[636]\ttrain-mlogloss:0.602519\tval-mlogloss:0.784662\n",
      "[637]\ttrain-mlogloss:0.602298\tval-mlogloss:0.784681\n",
      "[638]\ttrain-mlogloss:0.602022\tval-mlogloss:0.784602\n",
      "[639]\ttrain-mlogloss:0.601756\tval-mlogloss:0.784535\n",
      "[640]\ttrain-mlogloss:0.601617\tval-mlogloss:0.784502\n",
      "[641]\ttrain-mlogloss:0.601380\tval-mlogloss:0.784492\n",
      "[642]\ttrain-mlogloss:0.601182\tval-mlogloss:0.784452\n",
      "[643]\ttrain-mlogloss:0.600964\tval-mlogloss:0.784452\n",
      "[644]\ttrain-mlogloss:0.600737\tval-mlogloss:0.784417\n",
      "[645]\ttrain-mlogloss:0.600485\tval-mlogloss:0.784368\n",
      "[646]\ttrain-mlogloss:0.600280\tval-mlogloss:0.784413\n",
      "[647]\ttrain-mlogloss:0.600096\tval-mlogloss:0.784449\n",
      "[648]\ttrain-mlogloss:0.599880\tval-mlogloss:0.784498\n",
      "[649]\ttrain-mlogloss:0.599632\tval-mlogloss:0.784559\n",
      "[650]\ttrain-mlogloss:0.599448\tval-mlogloss:0.784498\n",
      "[651]\ttrain-mlogloss:0.599207\tval-mlogloss:0.784470\n",
      "[652]\ttrain-mlogloss:0.598931\tval-mlogloss:0.784432\n",
      "[653]\ttrain-mlogloss:0.598651\tval-mlogloss:0.784363\n",
      "[654]\ttrain-mlogloss:0.598431\tval-mlogloss:0.784371\n",
      "[655]\ttrain-mlogloss:0.598135\tval-mlogloss:0.784312\n",
      "[656]\ttrain-mlogloss:0.597917\tval-mlogloss:0.784338\n",
      "[657]\ttrain-mlogloss:0.597692\tval-mlogloss:0.784383\n",
      "[658]\ttrain-mlogloss:0.597487\tval-mlogloss:0.784352\n",
      "[659]\ttrain-mlogloss:0.597245\tval-mlogloss:0.784328\n",
      "[660]\ttrain-mlogloss:0.597051\tval-mlogloss:0.784341\n",
      "[661]\ttrain-mlogloss:0.596811\tval-mlogloss:0.784251\n",
      "[662]\ttrain-mlogloss:0.596598\tval-mlogloss:0.784278\n",
      "[663]\ttrain-mlogloss:0.596381\tval-mlogloss:0.784261\n",
      "[664]\ttrain-mlogloss:0.596087\tval-mlogloss:0.784262\n",
      "[665]\ttrain-mlogloss:0.595824\tval-mlogloss:0.784223\n",
      "[666]\ttrain-mlogloss:0.595584\tval-mlogloss:0.784233\n",
      "[667]\ttrain-mlogloss:0.595357\tval-mlogloss:0.784257\n",
      "[668]\ttrain-mlogloss:0.595155\tval-mlogloss:0.784216\n",
      "[669]\ttrain-mlogloss:0.594976\tval-mlogloss:0.784192\n",
      "[670]\ttrain-mlogloss:0.594784\tval-mlogloss:0.784304\n",
      "[671]\ttrain-mlogloss:0.594542\tval-mlogloss:0.784366\n",
      "[672]\ttrain-mlogloss:0.594289\tval-mlogloss:0.784302\n",
      "[673]\ttrain-mlogloss:0.594059\tval-mlogloss:0.784262\n",
      "[674]\ttrain-mlogloss:0.593919\tval-mlogloss:0.784190\n",
      "[675]\ttrain-mlogloss:0.593728\tval-mlogloss:0.784192\n",
      "[676]\ttrain-mlogloss:0.593497\tval-mlogloss:0.784128\n",
      "[677]\ttrain-mlogloss:0.593344\tval-mlogloss:0.784026\n",
      "[678]\ttrain-mlogloss:0.593085\tval-mlogloss:0.783947\n",
      "[679]\ttrain-mlogloss:0.592880\tval-mlogloss:0.783906\n",
      "[680]\ttrain-mlogloss:0.592632\tval-mlogloss:0.783908\n",
      "[681]\ttrain-mlogloss:0.592393\tval-mlogloss:0.783890\n",
      "[682]\ttrain-mlogloss:0.592201\tval-mlogloss:0.783826\n",
      "[683]\ttrain-mlogloss:0.591997\tval-mlogloss:0.783785\n",
      "[684]\ttrain-mlogloss:0.591789\tval-mlogloss:0.783771\n",
      "[685]\ttrain-mlogloss:0.591555\tval-mlogloss:0.783826\n",
      "[686]\ttrain-mlogloss:0.591369\tval-mlogloss:0.783850\n",
      "[687]\ttrain-mlogloss:0.591175\tval-mlogloss:0.783857\n",
      "[688]\ttrain-mlogloss:0.590963\tval-mlogloss:0.783822\n",
      "[689]\ttrain-mlogloss:0.590771\tval-mlogloss:0.783860\n",
      "[690]\ttrain-mlogloss:0.590560\tval-mlogloss:0.783842\n",
      "[691]\ttrain-mlogloss:0.590378\tval-mlogloss:0.783890\n",
      "[692]\ttrain-mlogloss:0.590216\tval-mlogloss:0.783867\n",
      "[693]\ttrain-mlogloss:0.589983\tval-mlogloss:0.783861\n",
      "[694]\ttrain-mlogloss:0.589815\tval-mlogloss:0.783903\n",
      "[695]\ttrain-mlogloss:0.589550\tval-mlogloss:0.783853\n",
      "[696]\ttrain-mlogloss:0.589403\tval-mlogloss:0.783807\n",
      "[697]\ttrain-mlogloss:0.589171\tval-mlogloss:0.783816\n",
      "[698]\ttrain-mlogloss:0.588916\tval-mlogloss:0.783757\n",
      "[699]\ttrain-mlogloss:0.588731\tval-mlogloss:0.783776\n",
      "[700]\ttrain-mlogloss:0.588549\tval-mlogloss:0.783776\n",
      "[701]\ttrain-mlogloss:0.588313\tval-mlogloss:0.783759\n",
      "[702]\ttrain-mlogloss:0.588092\tval-mlogloss:0.783727\n",
      "[703]\ttrain-mlogloss:0.587911\tval-mlogloss:0.783661\n",
      "[704]\ttrain-mlogloss:0.587756\tval-mlogloss:0.783714\n",
      "[705]\ttrain-mlogloss:0.587585\tval-mlogloss:0.783707\n",
      "[706]\ttrain-mlogloss:0.587403\tval-mlogloss:0.783694\n",
      "[707]\ttrain-mlogloss:0.587222\tval-mlogloss:0.783698\n",
      "[708]\ttrain-mlogloss:0.587078\tval-mlogloss:0.783680\n",
      "[709]\ttrain-mlogloss:0.586890\tval-mlogloss:0.783677\n",
      "[710]\ttrain-mlogloss:0.586670\tval-mlogloss:0.783691\n",
      "[711]\ttrain-mlogloss:0.586446\tval-mlogloss:0.783716\n",
      "[712]\ttrain-mlogloss:0.586243\tval-mlogloss:0.783682\n",
      "[713]\ttrain-mlogloss:0.585964\tval-mlogloss:0.783634\n",
      "[714]\ttrain-mlogloss:0.585738\tval-mlogloss:0.783718\n",
      "[715]\ttrain-mlogloss:0.585458\tval-mlogloss:0.783687\n",
      "[716]\ttrain-mlogloss:0.585249\tval-mlogloss:0.783734\n",
      "[717]\ttrain-mlogloss:0.585031\tval-mlogloss:0.783711\n",
      "[718]\ttrain-mlogloss:0.584909\tval-mlogloss:0.783670\n",
      "[719]\ttrain-mlogloss:0.584626\tval-mlogloss:0.783599\n",
      "[720]\ttrain-mlogloss:0.584456\tval-mlogloss:0.783615\n",
      "[721]\ttrain-mlogloss:0.584218\tval-mlogloss:0.783569\n",
      "[722]\ttrain-mlogloss:0.584029\tval-mlogloss:0.783575\n",
      "[723]\ttrain-mlogloss:0.583828\tval-mlogloss:0.783542\n",
      "[724]\ttrain-mlogloss:0.583599\tval-mlogloss:0.783552\n",
      "[725]\ttrain-mlogloss:0.583424\tval-mlogloss:0.783570\n",
      "[726]\ttrain-mlogloss:0.583218\tval-mlogloss:0.783540\n",
      "[727]\ttrain-mlogloss:0.583056\tval-mlogloss:0.783570\n",
      "[728]\ttrain-mlogloss:0.582815\tval-mlogloss:0.783556\n",
      "[729]\ttrain-mlogloss:0.582625\tval-mlogloss:0.783583\n",
      "[730]\ttrain-mlogloss:0.582404\tval-mlogloss:0.783594\n",
      "[731]\ttrain-mlogloss:0.582216\tval-mlogloss:0.783633\n",
      "[732]\ttrain-mlogloss:0.582051\tval-mlogloss:0.783571\n",
      "[733]\ttrain-mlogloss:0.581860\tval-mlogloss:0.783569\n",
      "[734]\ttrain-mlogloss:0.581630\tval-mlogloss:0.783566\n",
      "[735]\ttrain-mlogloss:0.581419\tval-mlogloss:0.783520\n",
      "[736]\ttrain-mlogloss:0.581188\tval-mlogloss:0.783457\n",
      "[737]\ttrain-mlogloss:0.581004\tval-mlogloss:0.783476\n",
      "[738]\ttrain-mlogloss:0.580805\tval-mlogloss:0.783463\n",
      "[739]\ttrain-mlogloss:0.580625\tval-mlogloss:0.783431\n",
      "[740]\ttrain-mlogloss:0.580499\tval-mlogloss:0.783391\n",
      "[741]\ttrain-mlogloss:0.580278\tval-mlogloss:0.783424\n",
      "[742]\ttrain-mlogloss:0.580060\tval-mlogloss:0.783397\n",
      "[743]\ttrain-mlogloss:0.579880\tval-mlogloss:0.783346\n",
      "[744]\ttrain-mlogloss:0.579702\tval-mlogloss:0.783322\n",
      "[745]\ttrain-mlogloss:0.579557\tval-mlogloss:0.783381\n",
      "[746]\ttrain-mlogloss:0.579427\tval-mlogloss:0.783391\n",
      "[747]\ttrain-mlogloss:0.579233\tval-mlogloss:0.783367\n",
      "[748]\ttrain-mlogloss:0.579050\tval-mlogloss:0.783384\n",
      "[749]\ttrain-mlogloss:0.578854\tval-mlogloss:0.783413\n",
      "[750]\ttrain-mlogloss:0.578674\tval-mlogloss:0.783349\n",
      "[751]\ttrain-mlogloss:0.578467\tval-mlogloss:0.783369\n",
      "[752]\ttrain-mlogloss:0.578259\tval-mlogloss:0.783243\n",
      "[753]\ttrain-mlogloss:0.578041\tval-mlogloss:0.783202\n",
      "[754]\ttrain-mlogloss:0.577813\tval-mlogloss:0.783223\n",
      "[755]\ttrain-mlogloss:0.577564\tval-mlogloss:0.783148\n",
      "[756]\ttrain-mlogloss:0.577373\tval-mlogloss:0.783105\n",
      "[757]\ttrain-mlogloss:0.577199\tval-mlogloss:0.783105\n",
      "[758]\ttrain-mlogloss:0.577010\tval-mlogloss:0.783104\n",
      "[759]\ttrain-mlogloss:0.576813\tval-mlogloss:0.783141\n",
      "[760]\ttrain-mlogloss:0.576641\tval-mlogloss:0.783115\n",
      "[761]\ttrain-mlogloss:0.576438\tval-mlogloss:0.783040\n",
      "[762]\ttrain-mlogloss:0.576255\tval-mlogloss:0.783023\n",
      "[763]\ttrain-mlogloss:0.576083\tval-mlogloss:0.783050\n",
      "[764]\ttrain-mlogloss:0.575909\tval-mlogloss:0.783006\n",
      "[765]\ttrain-mlogloss:0.575761\tval-mlogloss:0.783074\n",
      "[766]\ttrain-mlogloss:0.575548\tval-mlogloss:0.783074\n",
      "[767]\ttrain-mlogloss:0.575420\tval-mlogloss:0.783040\n",
      "[768]\ttrain-mlogloss:0.575176\tval-mlogloss:0.782969\n",
      "[769]\ttrain-mlogloss:0.575022\tval-mlogloss:0.782916\n",
      "[770]\ttrain-mlogloss:0.574834\tval-mlogloss:0.782937\n",
      "[771]\ttrain-mlogloss:0.574668\tval-mlogloss:0.782891\n",
      "[772]\ttrain-mlogloss:0.574410\tval-mlogloss:0.782867\n",
      "[773]\ttrain-mlogloss:0.574249\tval-mlogloss:0.782894\n",
      "[774]\ttrain-mlogloss:0.574032\tval-mlogloss:0.782887\n",
      "[775]\ttrain-mlogloss:0.573872\tval-mlogloss:0.782940\n",
      "[776]\ttrain-mlogloss:0.573679\tval-mlogloss:0.782887\n",
      "[777]\ttrain-mlogloss:0.573469\tval-mlogloss:0.782816\n",
      "[778]\ttrain-mlogloss:0.573255\tval-mlogloss:0.782836\n",
      "[779]\ttrain-mlogloss:0.573091\tval-mlogloss:0.782856\n",
      "[780]\ttrain-mlogloss:0.572895\tval-mlogloss:0.782852\n",
      "[781]\ttrain-mlogloss:0.572665\tval-mlogloss:0.782832\n",
      "[782]\ttrain-mlogloss:0.572468\tval-mlogloss:0.782856\n",
      "[783]\ttrain-mlogloss:0.572258\tval-mlogloss:0.782883\n",
      "[784]\ttrain-mlogloss:0.572070\tval-mlogloss:0.782945\n",
      "[785]\ttrain-mlogloss:0.571793\tval-mlogloss:0.782897\n",
      "[786]\ttrain-mlogloss:0.571616\tval-mlogloss:0.782941\n",
      "[787]\ttrain-mlogloss:0.571434\tval-mlogloss:0.782953\n",
      "[788]\ttrain-mlogloss:0.571244\tval-mlogloss:0.782930\n",
      "[789]\ttrain-mlogloss:0.571039\tval-mlogloss:0.782933\n",
      "[790]\ttrain-mlogloss:0.570906\tval-mlogloss:0.782893\n",
      "[791]\ttrain-mlogloss:0.570723\tval-mlogloss:0.782891\n",
      "[792]\ttrain-mlogloss:0.570529\tval-mlogloss:0.782887\n",
      "[793]\ttrain-mlogloss:0.570259\tval-mlogloss:0.782869\n",
      "[794]\ttrain-mlogloss:0.570029\tval-mlogloss:0.782904\n",
      "[795]\ttrain-mlogloss:0.569840\tval-mlogloss:0.782896\n",
      "[796]\ttrain-mlogloss:0.569601\tval-mlogloss:0.782816\n",
      "[797]\ttrain-mlogloss:0.569371\tval-mlogloss:0.782749\n",
      "[798]\ttrain-mlogloss:0.569183\tval-mlogloss:0.782716\n",
      "[799]\ttrain-mlogloss:0.569001\tval-mlogloss:0.782746\n",
      "[800]\ttrain-mlogloss:0.568804\tval-mlogloss:0.782702\n",
      "[801]\ttrain-mlogloss:0.568564\tval-mlogloss:0.782741\n",
      "[802]\ttrain-mlogloss:0.568375\tval-mlogloss:0.782688\n",
      "[803]\ttrain-mlogloss:0.568165\tval-mlogloss:0.782731\n",
      "[804]\ttrain-mlogloss:0.567994\tval-mlogloss:0.782716\n",
      "[805]\ttrain-mlogloss:0.567819\tval-mlogloss:0.782687\n",
      "[806]\ttrain-mlogloss:0.567570\tval-mlogloss:0.782665\n",
      "[807]\ttrain-mlogloss:0.567377\tval-mlogloss:0.782664\n",
      "[808]\ttrain-mlogloss:0.567234\tval-mlogloss:0.782706\n",
      "[809]\ttrain-mlogloss:0.567019\tval-mlogloss:0.782764\n",
      "[810]\ttrain-mlogloss:0.566848\tval-mlogloss:0.782759\n",
      "[811]\ttrain-mlogloss:0.566650\tval-mlogloss:0.782779\n",
      "[812]\ttrain-mlogloss:0.566497\tval-mlogloss:0.782752\n",
      "[813]\ttrain-mlogloss:0.566340\tval-mlogloss:0.782730\n",
      "[814]\ttrain-mlogloss:0.566123\tval-mlogloss:0.782679\n",
      "[815]\ttrain-mlogloss:0.565945\tval-mlogloss:0.782727\n",
      "[816]\ttrain-mlogloss:0.565733\tval-mlogloss:0.782730\n",
      "[817]\ttrain-mlogloss:0.565533\tval-mlogloss:0.782731\n",
      "[818]\ttrain-mlogloss:0.565296\tval-mlogloss:0.782792\n",
      "[819]\ttrain-mlogloss:0.565157\tval-mlogloss:0.782847\n",
      "[820]\ttrain-mlogloss:0.564969\tval-mlogloss:0.782892\n",
      "[821]\ttrain-mlogloss:0.564799\tval-mlogloss:0.782880\n",
      "[822]\ttrain-mlogloss:0.564550\tval-mlogloss:0.782846\n",
      "[823]\ttrain-mlogloss:0.564387\tval-mlogloss:0.782842\n",
      "[824]\ttrain-mlogloss:0.564247\tval-mlogloss:0.782911\n",
      "[825]\ttrain-mlogloss:0.564060\tval-mlogloss:0.782923\n",
      "[826]\ttrain-mlogloss:0.563876\tval-mlogloss:0.782977\n",
      "[827]\ttrain-mlogloss:0.563678\tval-mlogloss:0.782997\n",
      "[828]\ttrain-mlogloss:0.563424\tval-mlogloss:0.782933\n",
      "[829]\ttrain-mlogloss:0.563244\tval-mlogloss:0.782900\n",
      "[830]\ttrain-mlogloss:0.563091\tval-mlogloss:0.782845\n",
      "[831]\ttrain-mlogloss:0.562889\tval-mlogloss:0.782924\n",
      "[832]\ttrain-mlogloss:0.562697\tval-mlogloss:0.782915\n",
      "[833]\ttrain-mlogloss:0.562480\tval-mlogloss:0.782912\n",
      "[834]\ttrain-mlogloss:0.562355\tval-mlogloss:0.782901\n",
      "[835]\ttrain-mlogloss:0.562175\tval-mlogloss:0.782878\n",
      "[836]\ttrain-mlogloss:0.561966\tval-mlogloss:0.782930\n",
      "[837]\ttrain-mlogloss:0.561817\tval-mlogloss:0.782895\n",
      "[838]\ttrain-mlogloss:0.561636\tval-mlogloss:0.782875\n",
      "[839]\ttrain-mlogloss:0.561483\tval-mlogloss:0.782899\n",
      "[840]\ttrain-mlogloss:0.561297\tval-mlogloss:0.782871\n",
      "[841]\ttrain-mlogloss:0.561130\tval-mlogloss:0.782855\n",
      "[842]\ttrain-mlogloss:0.560917\tval-mlogloss:0.782901\n",
      "[843]\ttrain-mlogloss:0.560719\tval-mlogloss:0.782851\n",
      "[844]\ttrain-mlogloss:0.560537\tval-mlogloss:0.782789\n",
      "[845]\ttrain-mlogloss:0.560315\tval-mlogloss:0.782827\n",
      "[846]\ttrain-mlogloss:0.560132\tval-mlogloss:0.782811\n",
      "[847]\ttrain-mlogloss:0.559945\tval-mlogloss:0.782760\n",
      "[848]\ttrain-mlogloss:0.559787\tval-mlogloss:0.782784\n",
      "[849]\ttrain-mlogloss:0.559630\tval-mlogloss:0.782802\n",
      "[850]\ttrain-mlogloss:0.559424\tval-mlogloss:0.782798\n",
      "[851]\ttrain-mlogloss:0.559229\tval-mlogloss:0.782836\n",
      "[852]\ttrain-mlogloss:0.559057\tval-mlogloss:0.782832\n",
      "[853]\ttrain-mlogloss:0.558829\tval-mlogloss:0.782771\n",
      "[854]\ttrain-mlogloss:0.558616\tval-mlogloss:0.782751\n",
      "[855]\ttrain-mlogloss:0.558424\tval-mlogloss:0.782688\n",
      "[856]\ttrain-mlogloss:0.558220\tval-mlogloss:0.782673\n",
      "[857]\ttrain-mlogloss:0.558078\tval-mlogloss:0.782704\n",
      "[858]\ttrain-mlogloss:0.557860\tval-mlogloss:0.782722\n",
      "[859]\ttrain-mlogloss:0.557712\tval-mlogloss:0.782735\n",
      "[860]\ttrain-mlogloss:0.557554\tval-mlogloss:0.782740\n",
      "[861]\ttrain-mlogloss:0.557342\tval-mlogloss:0.782715\n",
      "[862]\ttrain-mlogloss:0.557150\tval-mlogloss:0.782750\n",
      "[863]\ttrain-mlogloss:0.556990\tval-mlogloss:0.782767\n",
      "[864]\ttrain-mlogloss:0.556830\tval-mlogloss:0.782821\n",
      "[865]\ttrain-mlogloss:0.556638\tval-mlogloss:0.782815\n",
      "[866]\ttrain-mlogloss:0.556425\tval-mlogloss:0.782756\n",
      "[867]\ttrain-mlogloss:0.556282\tval-mlogloss:0.782684\n",
      "[868]\ttrain-mlogloss:0.556038\tval-mlogloss:0.782712\n",
      "[869]\ttrain-mlogloss:0.555886\tval-mlogloss:0.782725\n",
      "[870]\ttrain-mlogloss:0.555694\tval-mlogloss:0.782741\n",
      "[871]\ttrain-mlogloss:0.555459\tval-mlogloss:0.782747\n",
      "[872]\ttrain-mlogloss:0.555254\tval-mlogloss:0.782791\n",
      "[873]\ttrain-mlogloss:0.555089\tval-mlogloss:0.782777\n",
      "[874]\ttrain-mlogloss:0.554883\tval-mlogloss:0.782794\n",
      "[875]\ttrain-mlogloss:0.554718\tval-mlogloss:0.782835\n",
      "[876]\ttrain-mlogloss:0.554524\tval-mlogloss:0.782821\n",
      "[877]\ttrain-mlogloss:0.554359\tval-mlogloss:0.782876\n",
      "[878]\ttrain-mlogloss:0.554230\tval-mlogloss:0.782820\n",
      "[879]\ttrain-mlogloss:0.554053\tval-mlogloss:0.782790\n",
      "[880]\ttrain-mlogloss:0.553850\tval-mlogloss:0.782790\n",
      "[881]\ttrain-mlogloss:0.553704\tval-mlogloss:0.782838\n",
      "[882]\ttrain-mlogloss:0.553572\tval-mlogloss:0.782789\n",
      "[883]\ttrain-mlogloss:0.553378\tval-mlogloss:0.782769\n",
      "[884]\ttrain-mlogloss:0.553149\tval-mlogloss:0.782860\n",
      "[885]\ttrain-mlogloss:0.553019\tval-mlogloss:0.782843\n",
      "[886]\ttrain-mlogloss:0.552827\tval-mlogloss:0.782869\n",
      "[887]\ttrain-mlogloss:0.552665\tval-mlogloss:0.782882\n",
      "[888]\ttrain-mlogloss:0.552531\tval-mlogloss:0.782868\n",
      "[889]\ttrain-mlogloss:0.552305\tval-mlogloss:0.782855\n",
      "[890]\ttrain-mlogloss:0.552107\tval-mlogloss:0.782855\n",
      "[891]\ttrain-mlogloss:0.551940\tval-mlogloss:0.782810\n",
      "[892]\ttrain-mlogloss:0.551733\tval-mlogloss:0.782796\n",
      "[893]\ttrain-mlogloss:0.551532\tval-mlogloss:0.782759\n",
      "[894]\ttrain-mlogloss:0.551321\tval-mlogloss:0.782745\n",
      "[895]\ttrain-mlogloss:0.551189\tval-mlogloss:0.782707\n",
      "[896]\ttrain-mlogloss:0.551038\tval-mlogloss:0.782715\n",
      "[897]\ttrain-mlogloss:0.550830\tval-mlogloss:0.782744\n",
      "[898]\ttrain-mlogloss:0.550610\tval-mlogloss:0.782728\n",
      "[899]\ttrain-mlogloss:0.550401\tval-mlogloss:0.782736\n",
      "[900]\ttrain-mlogloss:0.550149\tval-mlogloss:0.782744\n",
      "[901]\ttrain-mlogloss:0.549971\tval-mlogloss:0.782736\n",
      "[902]\ttrain-mlogloss:0.549802\tval-mlogloss:0.782705\n",
      "[903]\ttrain-mlogloss:0.549651\tval-mlogloss:0.782663\n",
      "[904]\ttrain-mlogloss:0.549426\tval-mlogloss:0.782691\n",
      "[905]\ttrain-mlogloss:0.549221\tval-mlogloss:0.782589\n",
      "[906]\ttrain-mlogloss:0.548997\tval-mlogloss:0.782611\n",
      "[907]\ttrain-mlogloss:0.548864\tval-mlogloss:0.782594\n",
      "[908]\ttrain-mlogloss:0.548654\tval-mlogloss:0.782556\n",
      "[909]\ttrain-mlogloss:0.548509\tval-mlogloss:0.782547\n",
      "[910]\ttrain-mlogloss:0.548327\tval-mlogloss:0.782509\n",
      "[911]\ttrain-mlogloss:0.548154\tval-mlogloss:0.782461\n",
      "[912]\ttrain-mlogloss:0.547945\tval-mlogloss:0.782449\n",
      "[913]\ttrain-mlogloss:0.547736\tval-mlogloss:0.782454\n",
      "[914]\ttrain-mlogloss:0.547530\tval-mlogloss:0.782424\n",
      "[915]\ttrain-mlogloss:0.547396\tval-mlogloss:0.782405\n",
      "[916]\ttrain-mlogloss:0.547292\tval-mlogloss:0.782353\n",
      "[917]\ttrain-mlogloss:0.547140\tval-mlogloss:0.782368\n",
      "[918]\ttrain-mlogloss:0.546925\tval-mlogloss:0.782357\n",
      "[919]\ttrain-mlogloss:0.546687\tval-mlogloss:0.782312\n",
      "[920]\ttrain-mlogloss:0.546548\tval-mlogloss:0.782296\n",
      "[921]\ttrain-mlogloss:0.546405\tval-mlogloss:0.782342\n",
      "[922]\ttrain-mlogloss:0.546242\tval-mlogloss:0.782385\n",
      "[923]\ttrain-mlogloss:0.546108\tval-mlogloss:0.782370\n",
      "[924]\ttrain-mlogloss:0.545948\tval-mlogloss:0.782320\n",
      "[925]\ttrain-mlogloss:0.545822\tval-mlogloss:0.782315\n",
      "[926]\ttrain-mlogloss:0.545651\tval-mlogloss:0.782310\n",
      "[927]\ttrain-mlogloss:0.545464\tval-mlogloss:0.782319\n",
      "[928]\ttrain-mlogloss:0.545224\tval-mlogloss:0.782309\n",
      "[929]\ttrain-mlogloss:0.545028\tval-mlogloss:0.782389\n",
      "[930]\ttrain-mlogloss:0.544853\tval-mlogloss:0.782413\n",
      "[931]\ttrain-mlogloss:0.544630\tval-mlogloss:0.782406\n",
      "[932]\ttrain-mlogloss:0.544425\tval-mlogloss:0.782351\n",
      "[933]\ttrain-mlogloss:0.544263\tval-mlogloss:0.782337\n",
      "[934]\ttrain-mlogloss:0.544069\tval-mlogloss:0.782310\n",
      "[935]\ttrain-mlogloss:0.543877\tval-mlogloss:0.782356\n",
      "[936]\ttrain-mlogloss:0.543677\tval-mlogloss:0.782341\n",
      "[937]\ttrain-mlogloss:0.543498\tval-mlogloss:0.782348\n",
      "[938]\ttrain-mlogloss:0.543237\tval-mlogloss:0.782371\n",
      "[939]\ttrain-mlogloss:0.543016\tval-mlogloss:0.782417\n",
      "[940]\ttrain-mlogloss:0.542829\tval-mlogloss:0.782422\n",
      "[941]\ttrain-mlogloss:0.542666\tval-mlogloss:0.782415\n",
      "[942]\ttrain-mlogloss:0.542514\tval-mlogloss:0.782408\n",
      "[943]\ttrain-mlogloss:0.542360\tval-mlogloss:0.782436\n",
      "[944]\ttrain-mlogloss:0.542137\tval-mlogloss:0.782457\n",
      "[945]\ttrain-mlogloss:0.541936\tval-mlogloss:0.782448\n",
      "[946]\ttrain-mlogloss:0.541737\tval-mlogloss:0.782399\n",
      "[947]\ttrain-mlogloss:0.541533\tval-mlogloss:0.782369\n",
      "[948]\ttrain-mlogloss:0.541364\tval-mlogloss:0.782377\n",
      "[949]\ttrain-mlogloss:0.541180\tval-mlogloss:0.782298\n",
      "[950]\ttrain-mlogloss:0.540957\tval-mlogloss:0.782320\n",
      "[951]\ttrain-mlogloss:0.540766\tval-mlogloss:0.782361\n",
      "[952]\ttrain-mlogloss:0.540578\tval-mlogloss:0.782359\n",
      "[953]\ttrain-mlogloss:0.540429\tval-mlogloss:0.782361\n",
      "[954]\ttrain-mlogloss:0.540217\tval-mlogloss:0.782313\n",
      "[955]\ttrain-mlogloss:0.540012\tval-mlogloss:0.782352\n",
      "[956]\ttrain-mlogloss:0.539822\tval-mlogloss:0.782382\n",
      "[957]\ttrain-mlogloss:0.539661\tval-mlogloss:0.782328\n",
      "[958]\ttrain-mlogloss:0.539533\tval-mlogloss:0.782359\n",
      "[959]\ttrain-mlogloss:0.539364\tval-mlogloss:0.782385\n",
      "[960]\ttrain-mlogloss:0.539202\tval-mlogloss:0.782423\n",
      "[961]\ttrain-mlogloss:0.539033\tval-mlogloss:0.782435\n",
      "[962]\ttrain-mlogloss:0.538820\tval-mlogloss:0.782429\n",
      "[963]\ttrain-mlogloss:0.538654\tval-mlogloss:0.782423\n",
      "[964]\ttrain-mlogloss:0.538514\tval-mlogloss:0.782375\n",
      "[965]\ttrain-mlogloss:0.538322\tval-mlogloss:0.782328\n",
      "[966]\ttrain-mlogloss:0.538114\tval-mlogloss:0.782357\n",
      "[967]\ttrain-mlogloss:0.537920\tval-mlogloss:0.782394\n",
      "[968]\ttrain-mlogloss:0.537694\tval-mlogloss:0.782366\n",
      "[969]\ttrain-mlogloss:0.537515\tval-mlogloss:0.782320\n",
      "[970]\ttrain-mlogloss:0.537334\tval-mlogloss:0.782265\n",
      "[971]\ttrain-mlogloss:0.537171\tval-mlogloss:0.782279\n",
      "[972]\ttrain-mlogloss:0.536965\tval-mlogloss:0.782343\n",
      "[973]\ttrain-mlogloss:0.536799\tval-mlogloss:0.782343\n",
      "[974]\ttrain-mlogloss:0.536626\tval-mlogloss:0.782331\n",
      "[975]\ttrain-mlogloss:0.536461\tval-mlogloss:0.782336\n",
      "[976]\ttrain-mlogloss:0.536272\tval-mlogloss:0.782345\n",
      "[977]\ttrain-mlogloss:0.536088\tval-mlogloss:0.782365\n",
      "[978]\ttrain-mlogloss:0.535892\tval-mlogloss:0.782294\n",
      "[979]\ttrain-mlogloss:0.535767\tval-mlogloss:0.782260\n",
      "[980]\ttrain-mlogloss:0.535576\tval-mlogloss:0.782283\n",
      "[981]\ttrain-mlogloss:0.535395\tval-mlogloss:0.782274\n",
      "[982]\ttrain-mlogloss:0.535212\tval-mlogloss:0.782250\n",
      "[983]\ttrain-mlogloss:0.535053\tval-mlogloss:0.782239\n",
      "[984]\ttrain-mlogloss:0.534860\tval-mlogloss:0.782174\n",
      "[985]\ttrain-mlogloss:0.534707\tval-mlogloss:0.782185\n",
      "[986]\ttrain-mlogloss:0.534530\tval-mlogloss:0.782243\n",
      "[987]\ttrain-mlogloss:0.534416\tval-mlogloss:0.782225\n",
      "[988]\ttrain-mlogloss:0.534210\tval-mlogloss:0.782227\n",
      "[989]\ttrain-mlogloss:0.534075\tval-mlogloss:0.782179\n",
      "[990]\ttrain-mlogloss:0.533948\tval-mlogloss:0.782227\n",
      "[991]\ttrain-mlogloss:0.533823\tval-mlogloss:0.782212\n",
      "[992]\ttrain-mlogloss:0.533636\tval-mlogloss:0.782239\n",
      "[993]\ttrain-mlogloss:0.533462\tval-mlogloss:0.782219\n",
      "[994]\ttrain-mlogloss:0.533280\tval-mlogloss:0.782183\n",
      "[995]\ttrain-mlogloss:0.533148\tval-mlogloss:0.782221\n",
      "[996]\ttrain-mlogloss:0.533004\tval-mlogloss:0.782158\n",
      "[997]\ttrain-mlogloss:0.532838\tval-mlogloss:0.782063\n",
      "[998]\ttrain-mlogloss:0.532707\tval-mlogloss:0.782101\n",
      "[999]\ttrain-mlogloss:0.532546\tval-mlogloss:0.782100\n",
      "[1000]\ttrain-mlogloss:0.532430\tval-mlogloss:0.782072\n",
      "[1001]\ttrain-mlogloss:0.532270\tval-mlogloss:0.782115\n",
      "[1002]\ttrain-mlogloss:0.532146\tval-mlogloss:0.782150\n",
      "[1003]\ttrain-mlogloss:0.531965\tval-mlogloss:0.782124\n",
      "[1004]\ttrain-mlogloss:0.531761\tval-mlogloss:0.782107\n",
      "[1005]\ttrain-mlogloss:0.531562\tval-mlogloss:0.782066\n",
      "[1006]\ttrain-mlogloss:0.531359\tval-mlogloss:0.782162\n",
      "[1007]\ttrain-mlogloss:0.531175\tval-mlogloss:0.782221\n",
      "[1008]\ttrain-mlogloss:0.531087\tval-mlogloss:0.782252\n",
      "[1009]\ttrain-mlogloss:0.530899\tval-mlogloss:0.782228\n",
      "[1010]\ttrain-mlogloss:0.530742\tval-mlogloss:0.782215\n",
      "[1011]\ttrain-mlogloss:0.530566\tval-mlogloss:0.782173\n",
      "[1012]\ttrain-mlogloss:0.530383\tval-mlogloss:0.782115\n",
      "[1013]\ttrain-mlogloss:0.530220\tval-mlogloss:0.782087\n",
      "[1014]\ttrain-mlogloss:0.530053\tval-mlogloss:0.782074\n",
      "[1015]\ttrain-mlogloss:0.529933\tval-mlogloss:0.782114\n",
      "[1016]\ttrain-mlogloss:0.529736\tval-mlogloss:0.782122\n",
      "[1017]\ttrain-mlogloss:0.529555\tval-mlogloss:0.782127\n",
      "[1018]\ttrain-mlogloss:0.529326\tval-mlogloss:0.782081\n",
      "[1019]\ttrain-mlogloss:0.529113\tval-mlogloss:0.782049\n",
      "[1020]\ttrain-mlogloss:0.528904\tval-mlogloss:0.782031\n",
      "[1021]\ttrain-mlogloss:0.528730\tval-mlogloss:0.782027\n",
      "[1022]\ttrain-mlogloss:0.528566\tval-mlogloss:0.782064\n",
      "[1023]\ttrain-mlogloss:0.528424\tval-mlogloss:0.782077\n",
      "[1024]\ttrain-mlogloss:0.528248\tval-mlogloss:0.782068\n",
      "[1025]\ttrain-mlogloss:0.528099\tval-mlogloss:0.782081\n",
      "[1026]\ttrain-mlogloss:0.527939\tval-mlogloss:0.782084\n",
      "[1027]\ttrain-mlogloss:0.527783\tval-mlogloss:0.782109\n",
      "[1028]\ttrain-mlogloss:0.527654\tval-mlogloss:0.782102\n",
      "[1029]\ttrain-mlogloss:0.527514\tval-mlogloss:0.782131\n",
      "[1030]\ttrain-mlogloss:0.527340\tval-mlogloss:0.782170\n",
      "[1031]\ttrain-mlogloss:0.527195\tval-mlogloss:0.782174\n",
      "[1032]\ttrain-mlogloss:0.526998\tval-mlogloss:0.782258\n",
      "[1033]\ttrain-mlogloss:0.526801\tval-mlogloss:0.782259\n",
      "[1034]\ttrain-mlogloss:0.526611\tval-mlogloss:0.782302\n",
      "[1035]\ttrain-mlogloss:0.526452\tval-mlogloss:0.782269\n",
      "[1036]\ttrain-mlogloss:0.526301\tval-mlogloss:0.782283\n",
      "[1037]\ttrain-mlogloss:0.526103\tval-mlogloss:0.782262\n",
      "[1038]\ttrain-mlogloss:0.525932\tval-mlogloss:0.782220\n",
      "[1039]\ttrain-mlogloss:0.525782\tval-mlogloss:0.782255\n",
      "[1040]\ttrain-mlogloss:0.525625\tval-mlogloss:0.782271\n",
      "[1041]\ttrain-mlogloss:0.525458\tval-mlogloss:0.782262\n",
      "[1042]\ttrain-mlogloss:0.525278\tval-mlogloss:0.782271\n",
      "[1043]\ttrain-mlogloss:0.525140\tval-mlogloss:0.782282\n",
      "[1044]\ttrain-mlogloss:0.524990\tval-mlogloss:0.782301\n",
      "[1045]\ttrain-mlogloss:0.524878\tval-mlogloss:0.782301\n",
      "[1046]\ttrain-mlogloss:0.524710\tval-mlogloss:0.782288\n",
      "[1047]\ttrain-mlogloss:0.524510\tval-mlogloss:0.782312\n",
      "[1048]\ttrain-mlogloss:0.524377\tval-mlogloss:0.782349\n",
      "[1049]\ttrain-mlogloss:0.524207\tval-mlogloss:0.782315\n",
      "[1050]\ttrain-mlogloss:0.523990\tval-mlogloss:0.782265\n",
      "[1051]\ttrain-mlogloss:0.523805\tval-mlogloss:0.782284\n",
      "[1052]\ttrain-mlogloss:0.523645\tval-mlogloss:0.782264\n",
      "[1053]\ttrain-mlogloss:0.523506\tval-mlogloss:0.782284\n",
      "[1054]\ttrain-mlogloss:0.523333\tval-mlogloss:0.782252\n",
      "[1055]\ttrain-mlogloss:0.523203\tval-mlogloss:0.782252\n",
      "[1056]\ttrain-mlogloss:0.523087\tval-mlogloss:0.782210\n",
      "[1057]\ttrain-mlogloss:0.522906\tval-mlogloss:0.782233\n",
      "[1058]\ttrain-mlogloss:0.522717\tval-mlogloss:0.782321\n",
      "[1059]\ttrain-mlogloss:0.522512\tval-mlogloss:0.782352\n",
      "[1060]\ttrain-mlogloss:0.522344\tval-mlogloss:0.782326\n",
      "[1061]\ttrain-mlogloss:0.522188\tval-mlogloss:0.782388\n",
      "[1062]\ttrain-mlogloss:0.522021\tval-mlogloss:0.782396\n",
      "[1063]\ttrain-mlogloss:0.521857\tval-mlogloss:0.782371\n",
      "[1064]\ttrain-mlogloss:0.521764\tval-mlogloss:0.782359\n",
      "[1065]\ttrain-mlogloss:0.521602\tval-mlogloss:0.782299\n",
      "[1066]\ttrain-mlogloss:0.521423\tval-mlogloss:0.782233\n",
      "[1067]\ttrain-mlogloss:0.521222\tval-mlogloss:0.782232\n",
      "[1068]\ttrain-mlogloss:0.521093\tval-mlogloss:0.782235\n",
      "[1069]\ttrain-mlogloss:0.520979\tval-mlogloss:0.782226\n",
      "[1070]\ttrain-mlogloss:0.520848\tval-mlogloss:0.782229\n",
      "[1071]\ttrain-mlogloss:0.520637\tval-mlogloss:0.782241\n",
      "[1072]\ttrain-mlogloss:0.520446\tval-mlogloss:0.782260\n",
      "[1073]\ttrain-mlogloss:0.520252\tval-mlogloss:0.782301\n",
      "[1074]\ttrain-mlogloss:0.520025\tval-mlogloss:0.782268\n",
      "[1075]\ttrain-mlogloss:0.519853\tval-mlogloss:0.782286\n",
      "[1076]\ttrain-mlogloss:0.519636\tval-mlogloss:0.782254\n",
      "[1077]\ttrain-mlogloss:0.519507\tval-mlogloss:0.782227\n",
      "[1078]\ttrain-mlogloss:0.519339\tval-mlogloss:0.782212\n",
      "[1079]\ttrain-mlogloss:0.519167\tval-mlogloss:0.782185\n",
      "[1080]\ttrain-mlogloss:0.519037\tval-mlogloss:0.782226\n",
      "[1081]\ttrain-mlogloss:0.518827\tval-mlogloss:0.782247\n",
      "[1082]\ttrain-mlogloss:0.518644\tval-mlogloss:0.782196\n",
      "[1083]\ttrain-mlogloss:0.518473\tval-mlogloss:0.782272\n",
      "[1084]\ttrain-mlogloss:0.518312\tval-mlogloss:0.782324\n",
      "[1085]\ttrain-mlogloss:0.518100\tval-mlogloss:0.782324\n",
      "[1086]\ttrain-mlogloss:0.517955\tval-mlogloss:0.782305\n",
      "[1087]\ttrain-mlogloss:0.517833\tval-mlogloss:0.782335\n",
      "[1088]\ttrain-mlogloss:0.517675\tval-mlogloss:0.782325\n",
      "[1089]\ttrain-mlogloss:0.517532\tval-mlogloss:0.782368\n",
      "[1090]\ttrain-mlogloss:0.517403\tval-mlogloss:0.782382\n",
      "[1091]\ttrain-mlogloss:0.517250\tval-mlogloss:0.782404\n",
      "[1092]\ttrain-mlogloss:0.517162\tval-mlogloss:0.782382\n",
      "[1093]\ttrain-mlogloss:0.516984\tval-mlogloss:0.782317\n",
      "[1094]\ttrain-mlogloss:0.516789\tval-mlogloss:0.782272\n",
      "[1095]\ttrain-mlogloss:0.516582\tval-mlogloss:0.782282\n",
      "[1096]\ttrain-mlogloss:0.516372\tval-mlogloss:0.782265\n",
      "[1097]\ttrain-mlogloss:0.516230\tval-mlogloss:0.782260\n",
      "[1098]\ttrain-mlogloss:0.516053\tval-mlogloss:0.782279\n",
      "[1099]\ttrain-mlogloss:0.515888\tval-mlogloss:0.782329\n",
      "[1100]\ttrain-mlogloss:0.515654\tval-mlogloss:0.782326\n",
      "[1101]\ttrain-mlogloss:0.515504\tval-mlogloss:0.782336\n",
      "[1102]\ttrain-mlogloss:0.515348\tval-mlogloss:0.782338\n",
      "[1103]\ttrain-mlogloss:0.515174\tval-mlogloss:0.782312\n",
      "[1104]\ttrain-mlogloss:0.515005\tval-mlogloss:0.782298\n",
      "[1105]\ttrain-mlogloss:0.514833\tval-mlogloss:0.782341\n",
      "[1106]\ttrain-mlogloss:0.514665\tval-mlogloss:0.782403\n",
      "[1107]\ttrain-mlogloss:0.514502\tval-mlogloss:0.782438\n",
      "[1108]\ttrain-mlogloss:0.514345\tval-mlogloss:0.782471\n",
      "[1109]\ttrain-mlogloss:0.514191\tval-mlogloss:0.782457\n",
      "[1110]\ttrain-mlogloss:0.514009\tval-mlogloss:0.782405\n",
      "[1111]\ttrain-mlogloss:0.513831\tval-mlogloss:0.782432\n",
      "[1112]\ttrain-mlogloss:0.513685\tval-mlogloss:0.782455\n",
      "[1113]\ttrain-mlogloss:0.513542\tval-mlogloss:0.782457\n",
      "[1114]\ttrain-mlogloss:0.513318\tval-mlogloss:0.782358\n",
      "[1115]\ttrain-mlogloss:0.513153\tval-mlogloss:0.782368\n",
      "[1116]\ttrain-mlogloss:0.512957\tval-mlogloss:0.782300\n",
      "[1117]\ttrain-mlogloss:0.512793\tval-mlogloss:0.782364\n",
      "[1118]\ttrain-mlogloss:0.512687\tval-mlogloss:0.782364\n",
      "[1119]\ttrain-mlogloss:0.512549\tval-mlogloss:0.782360\n",
      "[1120]\ttrain-mlogloss:0.512386\tval-mlogloss:0.782335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best score:', 0.782027)\n",
      "('Best iteration:', 1021)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1121]\ttrain-mlogloss:0.512219\tval-mlogloss:0.782342\n",
      "Stopping. Best iteration:\n",
      "[1021]\ttrain-mlogloss:0.528730\tval-mlogloss:0.782027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\"objective\": \"multi:softprob\"\n",
    "          , \"num_class\": 6\n",
    "          , \"booster\":  \"gbtree\"\n",
    "          , \"eval_metric\":  \"mlogloss\"\n",
    "          , \"eta\": 0.02\n",
    "          , \"subsample\": 0.7\n",
    "          , \"colsample_bytree\": 0.7\n",
    "          , \"max_depth\": 6\n",
    "          , \"min_child_weight\": 1\n",
    "          , \"seed\" : 1234\n",
    "         }\n",
    "\n",
    "model = xgb_train(train_X, train_y, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validate for base line performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "[CV] colsample_bytree=0.7, silent=True, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=True, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.774030 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=True, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks       | elapsed:  1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7, silent=True, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.753001 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=True, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=True, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.761113 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=True, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=True, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.756375 - 1.2min\n",
      "Best score: -0.761\n",
      "('Best parameters set:', {'colsample_bytree': 0.7, 'silent': True, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 1, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 6})\n",
      "('Scores:', [mean: -0.76113, std: 0.00799, params: {'colsample_bytree': 0.7, 'silent': True, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 1, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 6}])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 tasks       | elapsed:  4.9min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.9min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"objective\": [\"multi:softprob\"]\n",
    "              , \"learning_rate\": [0.02]\n",
    "              , \"max_depth\": [6]\n",
    "              , \"min_child_weight\": [1]\n",
    "              , \"n_estimators\": [1021]   #<best iteration (rounds) from last step 1, e.g. [1000]>\n",
    "              , \"subsample\": [0.7]\n",
    "              , \"colsample_bytree\": [0.7]\n",
    "              , \"nthread\": [-1]\n",
    "              , \"silent\" : [True]\n",
    "              , \"seed\": [1234]}\n",
    "\n",
    "model = search_model(train_X\n",
    "            , train_y\n",
    "            , xgb.XGBClassifier()\n",
    "            , param_grid\n",
    "            , 1\n",
    "            , 4\n",
    "            , False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step2 - tune max_depth and min_child_weight\n",
    "\n",
    "###### Use learning rate 0.02 and the optimal rounds we got from step two, the do grid search for max_depth and min_child_weight\n",
    "###### You can also plot the correlation between "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.780728 - 1.1min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks       | elapsed:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.758178 - 1.1min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.766426 - 1.1min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.761541 - 1.0min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 tasks       | elapsed:  4.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.781054 - 1.0min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.759038 - 1.0min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.767355 - 1.0min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 tasks       | elapsed:  7.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.761783 -  58.4s\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.781695 - 1.0min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.760726 - 1.0min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.768171 - 1.0min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.762244 - 1.0min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 tasks       | elapsed: 12.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.782060 - 1.0min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.761501 - 1.0min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.768855 - 1.0min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.762842 - 1.1min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.783538 -  59.3s\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks       | elapsed: 17.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.762788 -  58.6s\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.770169 -  56.1s\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=5, score=-0.763757 - 1.0min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.774030 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.753001 - 1.1min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.761113 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.756375 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 tasks       | elapsed: 25.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.774778 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.753202 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.762730 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.755682 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.775755 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.755515 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.763134 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  31 tasks       | elapsed: 33.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.756376 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.776935 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.756810 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.764407 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.757457 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.778421 - 1.1min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.757722 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.765862 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=6, score=-0.758188 - 1.2min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed: 44.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.771815 - 1.4min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.750326 - 1.4min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.759654 - 1.4min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.752240 - 1.4min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.770912 - 1.4min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.751231 - 1.5min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.760194 - 1.5min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.752155 - 1.5min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.772517 - 1.5min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed: 57.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.753173 - 1.5min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.761472 - 1.5min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.752290 - 1.4min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.774607 - 1.5min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.754303 - 1.4min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.762288 - 1.5min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.753165 - 1.5min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.775861 - 1.5min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.755747 - 1.4min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.763460 - 1.4min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=7, score=-0.754951 - 1.5min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 tasks       | elapsed: 73.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.773080 - 1.7min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.749978 - 1.8min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.760817 - 1.7min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.751197 - 1.7min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.771528 - 1.7min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.748867 - 1.7min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.761644 - 1.8min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.751042 - 1.7min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.772017 - 1.7min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.751999 - 1.7min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.761628 - 1.6min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  71 tasks       | elapsed: 92.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.750317 - 1.7min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.773864 - 1.6min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.753483 - 1.7min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.762545 - 1.7min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.751816 - 1.6min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.775736 - 1.6min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.755077 - 1.6min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.764128 - 1.6min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=8, score=-0.753688 - 1.6min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.777376 - 1.9min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.752821 - 2.0min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.768274 - 1.9min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=1, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.754430 - 2.0min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  84 tasks       | elapsed: 115.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.772504 - 1.9min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.751422 - 1.9min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.764233 - 1.9min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=3, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.751258 - 1.8min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.773308 - 1.8min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.753834 - 1.8min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.762945 - 1.9min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=5, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.750827 - 1.9min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.774503 - 1.7min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.754476 - 1.8min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.763689 - 1.8min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=7, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.752670 - 1.8min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.775990 - 1.7min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  97 tasks       | elapsed: 138.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.755938 - 1.6min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.764918 - 1.6min\n",
      "[CV] colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9 \n",
      "[CV]  colsample_bytree=0.7, silent=False, learning_rate=0.02, nthread=-1, min_child_weight=9, n_estimators=1021, subsample=0.7, seed=1234, objective=multi:softprob, max_depth=9, score=-0.754472 - 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed: 143.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.758\n",
      "('Best parameters set:', {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 3, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 8})\n",
      "('Scores:', [mean: -0.76672, std: 0.00860, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 1, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 5}, mean: -0.76731, std: 0.00848, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 3, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 5}, mean: -0.76821, std: 0.00827, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 5, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 5}, mean: -0.76882, std: 0.00813, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 7, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 5}, mean: -0.77006, std: 0.00828, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 9, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 5}, mean: -0.76113, std: 0.00799, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 1, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 6}, mean: -0.76160, std: 0.00837, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 3, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 6}, mean: -0.76270, std: 0.00810, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 5, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 6}, mean: -0.76390, std: 0.00809, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 7, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 6}, mean: -0.76505, std: 0.00837, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 9, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 6}, mean: -0.75851, std: 0.00844, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 1, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 7}, mean: -0.75862, std: 0.00791, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 3, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 7}, mean: -0.75986, std: 0.00814, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 5, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 7}, mean: -0.76109, std: 0.00856, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 7, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 7}, mean: -0.76251, std: 0.00840, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 9, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 7}, mean: -0.75877, std: 0.00927, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 1, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 8}, mean: -0.75827, std: 0.00905, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 3, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 8}, mean: -0.75899, std: 0.00867, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 5, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 8}, mean: -0.76043, std: 0.00877, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 7, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 8}, mean: -0.76216, std: 0.00881, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 9, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 8}, mean: -0.76323, std: 0.01014, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 1, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 9}, mean: -0.75986, std: 0.00900, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 3, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 9}, mean: -0.76023, std: 0.00877, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 5, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 9}, mean: -0.76134, std: 0.00868, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 7, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 9}, mean: -0.76283, std: 0.00859, params: {'colsample_bytree': 0.7, 'silent': False, 'learning_rate': 0.02, 'nthread': -1, 'min_child_weight': 9, 'n_estimators': 1021, 'subsample': 0.7, 'seed': 1234, 'objective': 'multi:softprob', 'max_depth': 9}])\n",
      "('best max_depth:', 8)\n",
      "('best min_child_weight:', 3)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"objective\": [\"multi:softprob\"]\n",
    "              , \"learning_rate\": [0.02]\n",
    "              , \"max_depth\": [5,6,7,8,9]\n",
    "              , \"min_child_weight\": [1,3,5,7,9]\n",
    "              , \"n_estimators\": [1021]   #<best iteration (rounds) from last step 1, e.g. [1000]>\n",
    "              , \"subsample\": [0.7]\n",
    "              , \"colsample_bytree\": [0.7]\n",
    "              , \"nthread\": [-1]\n",
    "              , \"silent\" : [False]\n",
    "              , \"seed\": [1234]}\n",
    "\n",
    "model = search_model(train_X\n",
    "            , train_y\n",
    "            , xgb.XGBClassifier()\n",
    "            , param_grid\n",
    "            , 1\n",
    "            , 4\n",
    "            , True)\n",
    "\n",
    "print (\"best max_depth:\", model.best_params_['max_depth'])\n",
    "print (\"best min_child_weight:\", model.best_params_['min_child_weight'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step3 - tune colsample_bytre and sub_sample\n",
    "\n",
    "Use learning rate and the optimal rounds we got from step 1, max_depth and min_child_weight from step 2, the grid search for colsample_bytree and subsample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {\"objective\": [\"multi:softprob\"]\n",
    "              , \"learning_rate\": [0.02]\n",
    "              , \"max_depth\": [8] #<fill in with the best max_depth from step 2, e.g. [7]>\n",
    "              , \"min_child_weight\": [5] #<fill in with the best min_child_weight from last step, e.g. [1]>\n",
    "              , \"n_estimators\": [1021] #<fill in with best iteration (rounds) from last step, e.g. [1000]>\n",
    "              , \"subsample\": [0.5,0.6,0.7,0.8,0.9]\n",
    "              , \"colsample_bytree\": [0.5,0.6,0.7,0.8,0.9]\n",
    "              , \"nthread\": [-1]\n",
    "              , \"silent\" : [False]\n",
    "              , \"seed\": [1234]}\n",
    "\n",
    "model = search_model(full_data[:data_params['train_size']][full_cols].values\n",
    "            , full_data[:data_params['train_size']][data_params['tgt_col']].values.reshape(data_params['train_size'])\n",
    "            , xgb.XGBClassifier()\n",
    "            , param_grid\n",
    "            , 1\n",
    "            , 4\n",
    "            , True)\n",
    "\n",
    "print (\"best subsample:\", model.best_params_['subsample'])\n",
    "print (\"best colsample_bytree:\", model.best_params_['colsample_bytree'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 - decrease learning rate for better performace\n",
    "\n",
    "Use learning rate 0.01 tuned parameters max_depth, min_childe_weight, subsample and colsample_bytreee from step 2 and 3, repeat early stopping for better rounds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {     \"objective\": \"multi:softprob\"\n",
    "          , \"num_class\": 6\n",
    "          , \"booster\":  \"gbtree\"\n",
    "          , \"eval_metric\":  \"mlogloss\"\n",
    "          , \"eta\": 0.01\n",
    "          , \"subsample\": <fill in with the best subsample from step 3, e.g. 0.7>\n",
    "          , \"colsample_bytree\": <fill in with the best colsample_bytree from step 3, e.g. 0.7>\n",
    "          , \"max_depth\": <fill in with the best max_depth from step 2, e.g. 7>\n",
    "          , \"min_child_weight\": <fill in with the best min_child_weight from step 2, e.g.1>\n",
    "          , \"seed\" : 1234\n",
    "         }\n",
    "\n",
    "model = xgb_train(full_data[:data_params['train_size']][full_cols].fillna(-999).values\n",
    "                    ,full_data[:data_params['train_size']][data_params['tgt_col']].fillna(-999).values.reshape(data_params['train_size'])\n",
    "                    ,params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've got the tuned parameters for learning rate, rounds, max_depth, min_child_weight, colsample_bytree and subsple. Now cross validate your model to see the improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {\"objective\": [\"multi:softprob\"]\n",
    "              , \"learning_rate\": [0.001]\n",
    "              , \"max_depth\": [] #<fill in with the best max_depth from step 3, e.g. 0.7>\n",
    "              , \"min_child_weight\": [] #<fill in with the best min_child_weight from step 3, e.g. 0.7>\n",
    "              , \"n_estimators\": []   #<best iteration (rounds) from last step 1, e.g. [1000]>\n",
    "              , \"subsample\": [] #<fill in with the best subsample from step 3, e.g. 0.7>\n",
    "              , \"colsample_bytree\": [0.75] #<fill in with the best colsample_bytree from step 3, e.g. 0.7>\n",
    "              , \"nthread\": [-1]\n",
    "              , \"silent\" : [False]\n",
    "              , \"seed\": [1234]}\n",
    "\n",
    "model = search_model(full_data[:data_params['train_size']][full_cols].values\n",
    "            , full_data[:data_params['train_size']][data_params['tgt_col']].values.reshape(data_params['train_size'])\n",
    "            , xgb.XGBClassifier()\n",
    "            , param_grid\n",
    "            , 1\n",
    "            , 4\n",
    "            , True)\n",
    "\n",
    "print (\"best max_depth:\", model.best_params_['max_depth'])\n",
    "print (\"best min_child_weight:\", model.best_params_['min_child_weight'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Homework\n",
    "\n",
    "1. Early stopping is helpful to optimize the rounds needed. However it's somehow arbitary and can be improved by ensemble method. Hint: reverse the traing set and target for early stopping.\n",
    "2. Try to tune parameters that were not covered by this notebook, e.g. gamma, alpha, and check the impacts.\n",
    "3. There's a chance the parameters we tuned are not the best due to the step size, i.e. we may want to fine tune colsample_bytree and subsample by using smaller steps such as [0.5,0.52,0.54,0.56,0.58,0.60,0.62....0.9]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
